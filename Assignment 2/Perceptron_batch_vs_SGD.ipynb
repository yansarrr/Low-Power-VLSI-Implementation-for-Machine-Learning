{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "miniature-siemens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=2, out_features=1, bias=False)\n",
      ")\n",
      "[Parameter containing:\n",
      "tensor([[ 1., -1.]], requires_grad=True)]\n",
      "Epoch 0 - loss: 150.3333282470703\n",
      "Epoch 1 - loss: 6.120000839233398\n",
      "Epoch 2 - loss: 36.42483139038086\n",
      "Epoch 3 - loss: 18.104551315307617\n",
      "Epoch 4 - loss: 6.065778732299805\n",
      "Epoch 5 - loss: 10.36883544921875\n",
      "Epoch 6 - loss: 6.2322306632995605\n",
      "Epoch 7 - loss: 5.852260589599609\n",
      "Epoch 8 - loss: 6.088119983673096\n",
      "Epoch 9 - loss: 5.494865417480469\n",
      "Epoch 10 - loss: 5.574592590332031\n",
      "Epoch 11 - loss: 5.536750793457031\n",
      "Epoch 12 - loss: 5.476492404937744\n",
      "Epoch 13 - loss: 5.4938530921936035\n",
      "Epoch 14 - loss: 5.480627536773682\n",
      "Epoch 15 - loss: 5.477013111114502\n",
      "Epoch 16 - loss: 5.478647232055664\n",
      "Epoch 17 - loss: 5.476379871368408\n",
      "Epoch 18 - loss: 5.476480007171631\n",
      "Epoch 19 - loss: 5.4764628410339355\n",
      "Epoch 20 - loss: 5.47619104385376\n",
      "Epoch 21 - loss: 5.476251602172852\n",
      "Epoch 22 - loss: 5.476212978363037\n",
      "Epoch 23 - loss: 5.476190567016602\n",
      "Epoch 24 - loss: 5.476199626922607\n",
      "Epoch 25 - loss: 5.476192474365234\n",
      "Epoch 26 - loss: 5.476190567016602\n",
      "Epoch 27 - loss: 5.476191997528076\n",
      "Epoch 28 - loss: 5.476190090179443\n",
      "Epoch 29 - loss: 5.476190567016602\n",
      "Epoch 30 - loss: 5.476190090179443\n",
      "Epoch 31 - loss: 5.476190567016602\n",
      "Epoch 32 - loss: 5.47619104385376\n",
      "Epoch 33 - loss: 5.476190090179443\n",
      "Epoch 34 - loss: 5.476190090179443\n",
      "Epoch 35 - loss: 5.476190567016602\n",
      "Epoch 36 - loss: 5.476190090179443\n",
      "Epoch 37 - loss: 5.47619104385376\n",
      "Epoch 38 - loss: 5.47619104385376\n",
      "Epoch 39 - loss: 5.476190567016602\n",
      "Epoch 40 - loss: 5.47619104385376\n",
      "Epoch 41 - loss: 5.476188659667969\n",
      "Epoch 42 - loss: 5.476190090179443\n",
      "Epoch 43 - loss: 5.476189136505127\n",
      "Epoch 44 - loss: 5.476190090179443\n",
      "Epoch 45 - loss: 5.476191997528076\n",
      "Epoch 46 - loss: 5.476191997528076\n",
      "Epoch 47 - loss: 5.476190090179443\n",
      "Epoch 48 - loss: 5.476190567016602\n",
      "Epoch 49 - loss: 5.476190567016602\n",
      "Epoch 50 - loss: 5.476190090179443\n",
      "Epoch 51 - loss: 5.47619104385376\n",
      "Epoch 52 - loss: 5.476190567016602\n",
      "Epoch 53 - loss: 5.47619104385376\n",
      "Epoch 54 - loss: 5.47619104385376\n",
      "Epoch 55 - loss: 5.47619104385376\n",
      "Epoch 56 - loss: 5.476190567016602\n",
      "Epoch 57 - loss: 5.47619104385376\n",
      "Epoch 58 - loss: 5.47619104385376\n",
      "Epoch 59 - loss: 5.47619104385376\n",
      "Epoch 60 - loss: 5.476190567016602\n",
      "Epoch 61 - loss: 5.47619104385376\n",
      "Epoch 62 - loss: 5.47619104385376\n",
      "Epoch 63 - loss: 5.47619104385376\n",
      "Epoch 64 - loss: 5.476190567016602\n",
      "Epoch 65 - loss: 5.47619104385376\n",
      "Epoch 66 - loss: 5.47619104385376\n",
      "Epoch 67 - loss: 5.47619104385376\n",
      "Epoch 68 - loss: 5.476190567016602\n",
      "Epoch 69 - loss: 5.47619104385376\n",
      "Epoch 70 - loss: 5.47619104385376\n",
      "Epoch 71 - loss: 5.47619104385376\n",
      "Epoch 72 - loss: 5.476190567016602\n",
      "Epoch 73 - loss: 5.47619104385376\n",
      "Epoch 74 - loss: 5.47619104385376\n",
      "Epoch 75 - loss: 5.47619104385376\n",
      "Epoch 76 - loss: 5.476190567016602\n",
      "Epoch 77 - loss: 5.47619104385376\n",
      "Epoch 78 - loss: 5.47619104385376\n",
      "Epoch 79 - loss: 5.47619104385376\n",
      "Epoch 80 - loss: 5.476190567016602\n",
      "Epoch 81 - loss: 5.47619104385376\n",
      "Epoch 82 - loss: 5.47619104385376\n",
      "Epoch 83 - loss: 5.47619104385376\n",
      "Epoch 84 - loss: 5.476190567016602\n",
      "Epoch 85 - loss: 5.47619104385376\n",
      "Epoch 86 - loss: 5.47619104385376\n",
      "Epoch 87 - loss: 5.47619104385376\n",
      "Epoch 88 - loss: 5.476190567016602\n",
      "Epoch 89 - loss: 5.47619104385376\n",
      "Epoch 90 - loss: 5.47619104385376\n",
      "Epoch 91 - loss: 5.47619104385376\n",
      "Epoch 92 - loss: 5.476190567016602\n",
      "Epoch 93 - loss: 5.47619104385376\n",
      "Epoch 94 - loss: 5.47619104385376\n",
      "Epoch 95 - loss: 5.47619104385376\n",
      "Epoch 96 - loss: 5.476190567016602\n",
      "Epoch 97 - loss: 5.47619104385376\n",
      "Epoch 98 - loss: 5.47619104385376\n",
      "Epoch 99 - loss: 5.47619104385376\n",
      "Epoch 100 - loss: 5.476190567016602\n",
      "Epoch 101 - loss: 5.47619104385376\n",
      "Epoch 102 - loss: 5.47619104385376\n",
      "Epoch 103 - loss: 5.47619104385376\n",
      "Epoch 104 - loss: 5.476190567016602\n",
      "Epoch 105 - loss: 5.47619104385376\n",
      "Epoch 106 - loss: 5.47619104385376\n",
      "Epoch 107 - loss: 5.47619104385376\n",
      "Epoch 108 - loss: 5.476190567016602\n",
      "Epoch 109 - loss: 5.47619104385376\n",
      "Epoch 110 - loss: 5.47619104385376\n",
      "Epoch 111 - loss: 5.47619104385376\n",
      "Epoch 112 - loss: 5.476190567016602\n",
      "Epoch 113 - loss: 5.47619104385376\n",
      "Epoch 114 - loss: 5.47619104385376\n",
      "Epoch 115 - loss: 5.47619104385376\n",
      "Epoch 116 - loss: 5.476190567016602\n",
      "Epoch 117 - loss: 5.47619104385376\n",
      "Epoch 118 - loss: 5.47619104385376\n",
      "Epoch 119 - loss: 5.47619104385376\n",
      "Epoch 120 - loss: 5.476190567016602\n",
      "Epoch 121 - loss: 5.47619104385376\n",
      "Epoch 122 - loss: 5.47619104385376\n",
      "Epoch 123 - loss: 5.47619104385376\n",
      "Epoch 124 - loss: 5.476190567016602\n",
      "Epoch 125 - loss: 5.47619104385376\n",
      "Epoch 126 - loss: 5.47619104385376\n",
      "Epoch 127 - loss: 5.47619104385376\n",
      "Epoch 128 - loss: 5.476190567016602\n",
      "Epoch 129 - loss: 5.47619104385376\n",
      "Epoch 130 - loss: 5.47619104385376\n",
      "Epoch 131 - loss: 5.47619104385376\n",
      "Epoch 132 - loss: 5.476190567016602\n",
      "Epoch 133 - loss: 5.47619104385376\n",
      "Epoch 134 - loss: 5.47619104385376\n",
      "Epoch 135 - loss: 5.47619104385376\n",
      "Epoch 136 - loss: 5.476190567016602\n",
      "Epoch 137 - loss: 5.47619104385376\n",
      "Epoch 138 - loss: 5.47619104385376\n",
      "Epoch 139 - loss: 5.47619104385376\n",
      "Epoch 140 - loss: 5.476190567016602\n",
      "Epoch 141 - loss: 5.47619104385376\n",
      "Epoch 142 - loss: 5.47619104385376\n",
      "Epoch 143 - loss: 5.47619104385376\n",
      "Epoch 144 - loss: 5.476190567016602\n",
      "Epoch 145 - loss: 5.47619104385376\n",
      "Epoch 146 - loss: 5.47619104385376\n",
      "Epoch 147 - loss: 5.47619104385376\n",
      "Epoch 148 - loss: 5.476190567016602\n",
      "Epoch 149 - loss: 5.47619104385376\n",
      "Epoch 150 - loss: 5.47619104385376\n",
      "Epoch 151 - loss: 5.47619104385376\n",
      "Epoch 152 - loss: 5.476190567016602\n",
      "Epoch 153 - loss: 5.47619104385376\n",
      "Epoch 154 - loss: 5.47619104385376\n",
      "Epoch 155 - loss: 5.47619104385376\n",
      "Epoch 156 - loss: 5.476190567016602\n",
      "Epoch 157 - loss: 5.47619104385376\n",
      "Epoch 158 - loss: 5.47619104385376\n",
      "Epoch 159 - loss: 5.47619104385376\n",
      "Epoch 160 - loss: 5.476190567016602\n",
      "Epoch 161 - loss: 5.47619104385376\n",
      "Epoch 162 - loss: 5.47619104385376\n",
      "Epoch 163 - loss: 5.47619104385376\n",
      "Epoch 164 - loss: 5.476190567016602\n",
      "Epoch 165 - loss: 5.47619104385376\n",
      "Epoch 166 - loss: 5.47619104385376\n",
      "Epoch 167 - loss: 5.47619104385376\n",
      "Epoch 168 - loss: 5.476190567016602\n",
      "Epoch 169 - loss: 5.47619104385376\n",
      "Epoch 170 - loss: 5.47619104385376\n",
      "Epoch 171 - loss: 5.47619104385376\n",
      "Epoch 172 - loss: 5.476190567016602\n",
      "Epoch 173 - loss: 5.47619104385376\n",
      "Epoch 174 - loss: 5.47619104385376\n",
      "Epoch 175 - loss: 5.47619104385376\n",
      "Epoch 176 - loss: 5.476190567016602\n",
      "Epoch 177 - loss: 5.47619104385376\n",
      "Epoch 178 - loss: 5.47619104385376\n",
      "Epoch 179 - loss: 5.47619104385376\n",
      "Epoch 180 - loss: 5.476190567016602\n",
      "Epoch 181 - loss: 5.47619104385376\n",
      "Epoch 182 - loss: 5.47619104385376\n",
      "Epoch 183 - loss: 5.47619104385376\n",
      "Epoch 184 - loss: 5.476190567016602\n",
      "Epoch 185 - loss: 5.47619104385376\n",
      "Epoch 186 - loss: 5.47619104385376\n",
      "Epoch 187 - loss: 5.47619104385376\n",
      "Epoch 188 - loss: 5.476190567016602\n",
      "Epoch 189 - loss: 5.47619104385376\n",
      "Epoch 190 - loss: 5.47619104385376\n",
      "Epoch 191 - loss: 5.47619104385376\n",
      "Epoch 192 - loss: 5.476190567016602\n",
      "Epoch 193 - loss: 5.47619104385376\n",
      "Epoch 194 - loss: 5.47619104385376\n",
      "Epoch 195 - loss: 5.47619104385376\n",
      "Epoch 196 - loss: 5.476190567016602\n",
      "Epoch 197 - loss: 5.47619104385376\n",
      "Epoch 198 - loss: 5.47619104385376\n",
      "Epoch 199 - loss: 5.47619104385376\n",
      "Epoch 200 - loss: 5.476190567016602\n",
      "Epoch 201 - loss: 5.47619104385376\n",
      "Epoch 202 - loss: 5.47619104385376\n",
      "Epoch 203 - loss: 5.47619104385376\n",
      "Epoch 204 - loss: 5.476190567016602\n",
      "Epoch 205 - loss: 5.47619104385376\n",
      "Epoch 206 - loss: 5.47619104385376\n",
      "Epoch 207 - loss: 5.47619104385376\n",
      "Epoch 208 - loss: 5.476190567016602\n",
      "Epoch 209 - loss: 5.47619104385376\n",
      "Epoch 210 - loss: 5.47619104385376\n",
      "Epoch 211 - loss: 5.47619104385376\n",
      "Epoch 212 - loss: 5.476190567016602\n",
      "Epoch 213 - loss: 5.47619104385376\n",
      "Epoch 214 - loss: 5.47619104385376\n",
      "Epoch 215 - loss: 5.47619104385376\n",
      "Epoch 216 - loss: 5.476190567016602\n",
      "Epoch 217 - loss: 5.47619104385376\n",
      "Epoch 218 - loss: 5.47619104385376\n",
      "Epoch 219 - loss: 5.47619104385376\n",
      "Epoch 220 - loss: 5.476190567016602\n",
      "Epoch 221 - loss: 5.47619104385376\n",
      "Epoch 222 - loss: 5.47619104385376\n",
      "Epoch 223 - loss: 5.47619104385376\n",
      "Epoch 224 - loss: 5.476190567016602\n",
      "Epoch 225 - loss: 5.47619104385376\n",
      "Epoch 226 - loss: 5.47619104385376\n",
      "Epoch 227 - loss: 5.47619104385376\n",
      "Epoch 228 - loss: 5.476190567016602\n",
      "Epoch 229 - loss: 5.47619104385376\n",
      "Epoch 230 - loss: 5.47619104385376\n",
      "Epoch 231 - loss: 5.47619104385376\n",
      "Epoch 232 - loss: 5.476190567016602\n",
      "Epoch 233 - loss: 5.47619104385376\n",
      "Epoch 234 - loss: 5.47619104385376\n",
      "Epoch 235 - loss: 5.47619104385376\n",
      "Epoch 236 - loss: 5.476190567016602\n",
      "Epoch 237 - loss: 5.47619104385376\n",
      "Epoch 238 - loss: 5.47619104385376\n",
      "Epoch 239 - loss: 5.47619104385376\n",
      "Epoch 240 - loss: 5.476190567016602\n",
      "Epoch 241 - loss: 5.47619104385376\n",
      "Epoch 242 - loss: 5.47619104385376\n",
      "Epoch 243 - loss: 5.47619104385376\n",
      "Epoch 244 - loss: 5.476190567016602\n",
      "Epoch 245 - loss: 5.47619104385376\n",
      "Epoch 246 - loss: 5.47619104385376\n",
      "Epoch 247 - loss: 5.47619104385376\n",
      "Epoch 248 - loss: 5.476190567016602\n",
      "Epoch 249 - loss: 5.47619104385376\n",
      "Epoch 250 - loss: 5.47619104385376\n",
      "Epoch 251 - loss: 5.47619104385376\n",
      "Epoch 252 - loss: 5.476190567016602\n",
      "Epoch 253 - loss: 5.47619104385376\n",
      "Epoch 254 - loss: 5.47619104385376\n",
      "Epoch 255 - loss: 5.47619104385376\n",
      "Epoch 256 - loss: 5.476190567016602\n",
      "Epoch 257 - loss: 5.47619104385376\n",
      "Epoch 258 - loss: 5.47619104385376\n",
      "Epoch 259 - loss: 5.47619104385376\n",
      "Epoch 260 - loss: 5.476190567016602\n",
      "Epoch 261 - loss: 5.47619104385376\n",
      "Epoch 262 - loss: 5.47619104385376\n",
      "Epoch 263 - loss: 5.47619104385376\n",
      "Epoch 264 - loss: 5.476190567016602\n",
      "Epoch 265 - loss: 5.47619104385376\n",
      "Epoch 266 - loss: 5.47619104385376\n",
      "Epoch 267 - loss: 5.47619104385376\n",
      "Epoch 268 - loss: 5.476190567016602\n",
      "Epoch 269 - loss: 5.47619104385376\n",
      "Epoch 270 - loss: 5.47619104385376\n",
      "Epoch 271 - loss: 5.47619104385376\n",
      "Epoch 272 - loss: 5.476190567016602\n",
      "Epoch 273 - loss: 5.47619104385376\n",
      "Epoch 274 - loss: 5.47619104385376\n",
      "Epoch 275 - loss: 5.47619104385376\n",
      "Epoch 276 - loss: 5.476190567016602\n",
      "Epoch 277 - loss: 5.47619104385376\n",
      "Epoch 278 - loss: 5.47619104385376\n",
      "Epoch 279 - loss: 5.47619104385376\n",
      "Epoch 280 - loss: 5.476190567016602\n",
      "Epoch 281 - loss: 5.47619104385376\n",
      "Epoch 282 - loss: 5.47619104385376\n",
      "Epoch 283 - loss: 5.47619104385376\n",
      "Epoch 284 - loss: 5.476190567016602\n",
      "Epoch 285 - loss: 5.47619104385376\n",
      "Epoch 286 - loss: 5.47619104385376\n",
      "Epoch 287 - loss: 5.47619104385376\n",
      "Epoch 288 - loss: 5.476190567016602\n",
      "Epoch 289 - loss: 5.47619104385376\n",
      "Epoch 290 - loss: 5.47619104385376\n",
      "Epoch 291 - loss: 5.47619104385376\n",
      "Epoch 292 - loss: 5.476190567016602\n",
      "Epoch 293 - loss: 5.47619104385376\n",
      "Epoch 294 - loss: 5.47619104385376\n",
      "Epoch 295 - loss: 5.47619104385376\n",
      "Epoch 296 - loss: 5.476190567016602\n",
      "Epoch 297 - loss: 5.47619104385376\n",
      "Epoch 298 - loss: 5.47619104385376\n",
      "Epoch 299 - loss: 5.47619104385376\n",
      "when x = tensor([1., 3.]), y = tensor([3.5714], grad_fn=<SqueezeBackward4>)\n",
      "when x = tensor([2., 6.]), y = tensor([7.1429], grad_fn=<SqueezeBackward4>)\n",
      "when x = tensor([3., 9.]), y = tensor([10.7143], grad_fn=<SqueezeBackward4>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9fc2958100>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2,1,bias=False)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "\n",
    "net.fc1.weight = torch.nn.Parameter(torch.tensor([[1., -1.]], requires_grad=True))\n",
    "\n",
    "print(list(net.parameters()))\n",
    "\n",
    "#input = torch.randn(1,2)\n",
    "#out = net(input)\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "#def criterion(out, label):\n",
    "#    return ((label - out)**2).mean()\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.5)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.005)\n",
    "\n",
    "\n",
    "data = torch.tensor([[1.,3.], [2.,6.], [3.,9.]], dtype=torch.float)\n",
    "target = torch.tensor([[1.],[5.],[13.]], dtype=torch.float)\n",
    "\n",
    "hist = []\n",
    "\n",
    "############## Batch GD based update ##############       \n",
    "      \n",
    "for epoch in range(300):   \n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(data)\n",
    "    loss = criterion(outputs, target)\n",
    "    loss.backward()\n",
    "    hist.append(loss.detach())\n",
    "    optimizer.step()\n",
    "    print(\"Epoch {} - loss: {}\".format(epoch, loss))\n",
    "####################################################\n",
    "\n",
    "### Test the trained network ###\n",
    "for i, current_data in enumerate(data):\n",
    "    out = net(current_data)  \n",
    "    print(\"when x = {}, y = {}\".format(current_data, out))\n",
    "    \n",
    "plt.plot(hist, label = \"training curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fleet-packet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=2, out_features=1, bias=False)\n",
      ")\n",
      "[Parameter containing:\n",
      "tensor([[ 1., -1.]], requires_grad=True)]\n",
      "Epoch 0 - Data Point 0 - Loss: 9.0\n",
      "Epoch 0 - Data Point 1 - Loss: 60.840003967285156\n",
      "Epoch 0 - Data Point 2 - Loss: 48.16359329223633\n",
      "Epoch 1 - Data Point 0 - Loss: 47.52723693847656\n",
      "Epoch 1 - Data Point 1 - Loss: 193.33233642578125\n",
      "Epoch 1 - Data Point 2 - Loss: 1.0173128843307495\n",
      "Epoch 2 - Data Point 0 - Loss: 0.45298048853874207\n",
      "Epoch 2 - Data Point 1 - Loss: 24.202863693237305\n",
      "Epoch 2 - Data Point 2 - Loss: 88.83402252197266\n",
      "Epoch 3 - Data Point 0 - Loss: 41.247581481933594\n",
      "Epoch 3 - Data Point 1 - Loss: 182.4311065673828\n",
      "Epoch 3 - Data Point 2 - Loss: 1.685847282409668\n",
      "Epoch 4 - Data Point 0 - Loss: 0.5527670979499817\n",
      "Epoch 4 - Data Point 1 - Loss: 23.358642578125\n",
      "Epoch 4 - Data Point 2 - Loss: 89.11278533935547\n",
      "Epoch 5 - Data Point 0 - Loss: 40.98900604248047\n",
      "Epoch 5 - Data Point 1 - Loss: 181.1503143310547\n",
      "Epoch 5 - Data Point 2 - Loss: 1.635256290435791\n",
      "Epoch 6 - Data Point 0 - Loss: 0.573534369468689\n",
      "Epoch 6 - Data Point 1 - Loss: 22.94943618774414\n",
      "Epoch 6 - Data Point 2 - Loss: 88.66230010986328\n",
      "Epoch 7 - Data Point 0 - Loss: 40.82246398925781\n",
      "Epoch 7 - Data Point 1 - Loss: 180.02647399902344\n",
      "Epoch 7 - Data Point 2 - Loss: 1.5735151767730713\n",
      "Epoch 8 - Data Point 0 - Loss: 0.5932254791259766\n",
      "Epoch 8 - Data Point 1 - Loss: 22.552209854125977\n",
      "Epoch 8 - Data Point 2 - Loss: 88.20365142822266\n",
      "Epoch 9 - Data Point 0 - Loss: 40.65843963623047\n",
      "Epoch 9 - Data Point 1 - Loss: 178.91358947753906\n",
      "Epoch 9 - Data Point 2 - Loss: 1.5130443572998047\n",
      "Epoch 10 - Data Point 0 - Loss: 0.6131349205970764\n",
      "Epoch 10 - Data Point 1 - Loss: 22.160335540771484\n",
      "Epoch 10 - Data Point 2 - Loss: 87.74807739257812\n",
      "Epoch 11 - Data Point 0 - Loss: 40.49551010131836\n",
      "Epoch 11 - Data Point 1 - Loss: 177.80923461914062\n",
      "Epoch 11 - Data Point 2 - Loss: 1.4540135860443115\n",
      "Epoch 12 - Data Point 0 - Loss: 0.6332811117172241\n",
      "Epoch 12 - Data Point 1 - Loss: 21.77363395690918\n",
      "Epoch 12 - Data Point 2 - Loss: 87.29572296142578\n",
      "Epoch 13 - Data Point 0 - Loss: 40.33363723754883\n",
      "Epoch 13 - Data Point 1 - Loss: 176.7132568359375\n",
      "Epoch 13 - Data Point 2 - Loss: 1.396427869796753\n",
      "Epoch 14 - Data Point 0 - Loss: 0.6536576747894287\n",
      "Epoch 14 - Data Point 1 - Loss: 21.39208984375\n",
      "Epoch 14 - Data Point 2 - Loss: 86.84661102294922\n",
      "Epoch 15 - Data Point 0 - Loss: 40.17283630371094\n",
      "Epoch 15 - Data Point 1 - Loss: 175.6256866455078\n",
      "Epoch 15 - Data Point 2 - Loss: 1.3402595520019531\n",
      "Epoch 16 - Data Point 0 - Loss: 0.6742618083953857\n",
      "Epoch 16 - Data Point 1 - Loss: 21.01564598083496\n",
      "Epoch 16 - Data Point 2 - Loss: 86.40071105957031\n",
      "Epoch 17 - Data Point 0 - Loss: 40.01309585571289\n",
      "Epoch 17 - Data Point 1 - Loss: 174.54640197753906\n",
      "Epoch 17 - Data Point 2 - Loss: 1.2854949235916138\n",
      "Epoch 18 - Data Point 0 - Loss: 0.695088803768158\n",
      "Epoch 18 - Data Point 1 - Loss: 20.644245147705078\n",
      "Epoch 18 - Data Point 2 - Loss: 85.95800018310547\n",
      "Epoch 19 - Data Point 0 - Loss: 39.854400634765625\n",
      "Epoch 19 - Data Point 1 - Loss: 173.47537231445312\n",
      "Epoch 19 - Data Point 2 - Loss: 1.232109785079956\n",
      "Epoch 20 - Data Point 0 - Loss: 0.7161365151405334\n",
      "Epoch 20 - Data Point 1 - Loss: 20.27781105041504\n",
      "Epoch 20 - Data Point 2 - Loss: 85.51839447021484\n",
      "Epoch 21 - Data Point 0 - Loss: 39.69672393798828\n",
      "Epoch 21 - Data Point 1 - Loss: 172.41246032714844\n",
      "Epoch 21 - Data Point 2 - Loss: 1.180097222328186\n",
      "Epoch 22 - Data Point 0 - Loss: 0.7373993396759033\n",
      "Epoch 22 - Data Point 1 - Loss: 19.91631507873535\n",
      "Epoch 22 - Data Point 2 - Loss: 85.08194732666016\n",
      "Epoch 23 - Data Point 0 - Loss: 39.540077209472656\n",
      "Epoch 23 - Data Point 1 - Loss: 171.35763549804688\n",
      "Epoch 23 - Data Point 2 - Loss: 1.129433274269104\n",
      "Epoch 24 - Data Point 0 - Loss: 0.7588741183280945\n",
      "Epoch 24 - Data Point 1 - Loss: 19.5596923828125\n",
      "Epoch 24 - Data Point 2 - Loss: 84.64859771728516\n",
      "Epoch 25 - Data Point 0 - Loss: 39.38447570800781\n",
      "Epoch 25 - Data Point 1 - Loss: 170.31094360351562\n",
      "Epoch 25 - Data Point 2 - Loss: 1.0801048278808594\n",
      "Epoch 26 - Data Point 0 - Loss: 0.7805564403533936\n",
      "Epoch 26 - Data Point 1 - Loss: 19.207916259765625\n",
      "Epoch 26 - Data Point 2 - Loss: 84.21830749511719\n",
      "Epoch 27 - Data Point 0 - Loss: 39.229881286621094\n",
      "Epoch 27 - Data Point 1 - Loss: 169.2721710205078\n",
      "Epoch 27 - Data Point 2 - Loss: 1.032092809677124\n",
      "Epoch 28 - Data Point 0 - Loss: 0.802444577217102\n",
      "Epoch 28 - Data Point 1 - Loss: 18.860891342163086\n",
      "Epoch 28 - Data Point 2 - Loss: 83.79109191894531\n",
      "Epoch 29 - Data Point 0 - Loss: 39.0762939453125\n",
      "Epoch 29 - Data Point 1 - Loss: 168.2412109375\n",
      "Epoch 29 - Data Point 2 - Loss: 0.9853919744491577\n",
      "Epoch 30 - Data Point 0 - Loss: 0.8245315551757812\n",
      "Epoch 30 - Data Point 1 - Loss: 18.51861572265625\n",
      "Epoch 30 - Data Point 2 - Loss: 83.36691284179688\n",
      "Epoch 31 - Data Point 0 - Loss: 38.923702239990234\n",
      "Epoch 31 - Data Point 1 - Loss: 167.21820068359375\n",
      "Epoch 31 - Data Point 2 - Loss: 0.9399775266647339\n",
      "Epoch 32 - Data Point 0 - Loss: 0.8468149900436401\n",
      "Epoch 32 - Data Point 1 - Loss: 18.181028366088867\n",
      "Epoch 32 - Data Point 2 - Loss: 82.94575500488281\n",
      "Epoch 33 - Data Point 0 - Loss: 38.772117614746094\n",
      "Epoch 33 - Data Point 1 - Loss: 166.2029266357422\n",
      "Epoch 33 - Data Point 2 - Loss: 0.8958330154418945\n",
      "Epoch 34 - Data Point 0 - Loss: 0.8692919611930847\n",
      "Epoch 34 - Data Point 1 - Loss: 17.84805679321289\n",
      "Epoch 34 - Data Point 2 - Loss: 82.52757263183594\n",
      "Epoch 35 - Data Point 0 - Loss: 38.62151336669922\n",
      "Epoch 35 - Data Point 1 - Loss: 165.19546508789062\n",
      "Epoch 35 - Data Point 2 - Loss: 0.8529386520385742\n",
      "Epoch 36 - Data Point 0 - Loss: 0.8919594883918762\n",
      "Epoch 36 - Data Point 1 - Loss: 17.5196533203125\n",
      "Epoch 36 - Data Point 2 - Loss: 82.11231231689453\n",
      "Epoch 37 - Data Point 0 - Loss: 38.47188186645508\n",
      "Epoch 37 - Data Point 1 - Loss: 164.19544982910156\n",
      "Epoch 37 - Data Point 2 - Loss: 0.8112924098968506\n",
      "Epoch 38 - Data Point 0 - Loss: 0.9148129820823669\n",
      "Epoch 38 - Data Point 1 - Loss: 17.195783615112305\n",
      "Epoch 38 - Data Point 2 - Loss: 81.70002746582031\n",
      "Epoch 39 - Data Point 0 - Loss: 38.323219299316406\n",
      "Epoch 39 - Data Point 1 - Loss: 163.20309448242188\n",
      "Epoch 39 - Data Point 2 - Loss: 0.7708677053451538\n",
      "Epoch 40 - Data Point 0 - Loss: 0.9378498196601868\n",
      "Epoch 40 - Data Point 1 - Loss: 16.876386642456055\n",
      "Epoch 40 - Data Point 2 - Loss: 81.29064178466797\n",
      "Epoch 41 - Data Point 0 - Loss: 38.175533294677734\n",
      "Epoch 41 - Data Point 1 - Loss: 162.21827697753906\n",
      "Epoch 41 - Data Point 2 - Loss: 0.7316538095474243\n",
      "Epoch 42 - Data Point 0 - Loss: 0.9610660672187805\n",
      "Epoch 42 - Data Point 1 - Loss: 16.561420440673828\n",
      "Epoch 42 - Data Point 2 - Loss: 80.8841323852539\n",
      "Epoch 43 - Data Point 0 - Loss: 38.02879333496094\n",
      "Epoch 43 - Data Point 1 - Loss: 161.24090576171875\n",
      "Epoch 43 - Data Point 2 - Loss: 0.693635106086731\n",
      "Epoch 44 - Data Point 0 - Loss: 0.9844580292701721\n",
      "Epoch 44 - Data Point 1 - Loss: 16.250837326049805\n",
      "Epoch 44 - Data Point 2 - Loss: 80.48049926757812\n",
      "Epoch 45 - Data Point 0 - Loss: 37.882999420166016\n",
      "Epoch 45 - Data Point 1 - Loss: 160.27090454101562\n",
      "Epoch 45 - Data Point 2 - Loss: 0.6567976474761963\n",
      "Epoch 46 - Data Point 0 - Loss: 1.0080230236053467\n",
      "Epoch 46 - Data Point 1 - Loss: 15.944589614868164\n",
      "Epoch 46 - Data Point 2 - Loss: 80.0797119140625\n",
      "Epoch 47 - Data Point 0 - Loss: 37.73816680908203\n",
      "Epoch 47 - Data Point 1 - Loss: 159.30828857421875\n",
      "Epoch 47 - Data Point 2 - Loss: 0.6211260557174683\n",
      "Epoch 48 - Data Point 0 - Loss: 1.0317561626434326\n",
      "Epoch 48 - Data Point 1 - Loss: 15.642642974853516\n",
      "Epoch 48 - Data Point 2 - Loss: 79.6817626953125\n",
      "Epoch 49 - Data Point 0 - Loss: 37.59426498413086\n",
      "Epoch 49 - Data Point 1 - Loss: 158.35296630859375\n",
      "Epoch 49 - Data Point 2 - Loss: 0.5866096019744873\n",
      "Epoch 50 - Data Point 0 - Loss: 1.0556546449661255\n",
      "Epoch 50 - Data Point 1 - Loss: 15.344953536987305\n",
      "Epoch 50 - Data Point 2 - Loss: 79.28660583496094\n",
      "Epoch 51 - Data Point 0 - Loss: 37.4512939453125\n",
      "Epoch 51 - Data Point 1 - Loss: 157.4048309326172\n",
      "Epoch 51 - Data Point 2 - Loss: 0.5532287359237671\n",
      "Epoch 52 - Data Point 0 - Loss: 1.0797163248062134\n",
      "Epoch 52 - Data Point 1 - Loss: 15.0514554977417\n",
      "Epoch 52 - Data Point 2 - Loss: 78.89422607421875\n",
      "Epoch 53 - Data Point 0 - Loss: 37.30923843383789\n",
      "Epoch 53 - Data Point 1 - Loss: 156.4637908935547\n",
      "Epoch 53 - Data Point 2 - Loss: 0.5209743976593018\n",
      "Epoch 54 - Data Point 0 - Loss: 1.103936791419983\n",
      "Epoch 54 - Data Point 1 - Loss: 14.762120246887207\n",
      "Epoch 54 - Data Point 2 - Loss: 78.50464630126953\n",
      "Epoch 55 - Data Point 0 - Loss: 37.168121337890625\n",
      "Epoch 55 - Data Point 1 - Loss: 155.5299530029297\n",
      "Epoch 55 - Data Point 2 - Loss: 0.48982885479927063\n",
      "Epoch 56 - Data Point 0 - Loss: 1.1283130645751953\n",
      "Epoch 56 - Data Point 1 - Loss: 14.476899147033691\n",
      "Epoch 56 - Data Point 2 - Loss: 78.11776733398438\n",
      "Epoch 57 - Data Point 0 - Loss: 37.027896881103516\n",
      "Epoch 57 - Data Point 1 - Loss: 154.60316467285156\n",
      "Epoch 57 - Data Point 2 - Loss: 0.4597790241241455\n",
      "Epoch 58 - Data Point 0 - Loss: 1.1528418064117432\n",
      "Epoch 58 - Data Point 1 - Loss: 14.195751190185547\n",
      "Epoch 58 - Data Point 2 - Loss: 77.73362731933594\n",
      "Epoch 59 - Data Point 0 - Loss: 36.88858413696289\n",
      "Epoch 59 - Data Point 1 - Loss: 153.68331909179688\n",
      "Epoch 59 - Data Point 2 - Loss: 0.4308067560195923\n",
      "Epoch 60 - Data Point 0 - Loss: 1.1775225400924683\n",
      "Epoch 60 - Data Point 1 - Loss: 13.918590545654297\n",
      "Epoch 60 - Data Point 2 - Loss: 77.35214233398438\n",
      "Epoch 61 - Data Point 0 - Loss: 36.75017166137695\n",
      "Epoch 61 - Data Point 1 - Loss: 152.77041625976562\n",
      "Epoch 61 - Data Point 2 - Loss: 0.4029043912887573\n",
      "Epoch 62 - Data Point 0 - Loss: 1.2023496627807617\n",
      "Epoch 62 - Data Point 1 - Loss: 13.645424842834473\n",
      "Epoch 62 - Data Point 2 - Loss: 76.97335815429688\n",
      "Epoch 63 - Data Point 0 - Loss: 36.612632751464844\n",
      "Epoch 63 - Data Point 1 - Loss: 151.86436462402344\n",
      "Epoch 63 - Data Point 2 - Loss: 0.3760589063167572\n",
      "Epoch 64 - Data Point 0 - Loss: 1.2273201942443848\n",
      "Epoch 64 - Data Point 1 - Loss: 13.376198768615723\n",
      "Epoch 64 - Data Point 2 - Loss: 76.59722137451172\n",
      "Epoch 65 - Data Point 0 - Loss: 36.475990295410156\n",
      "Epoch 65 - Data Point 1 - Loss: 150.9651336669922\n",
      "Epoch 65 - Data Point 2 - Loss: 0.3502528965473175\n",
      "Epoch 66 - Data Point 0 - Loss: 1.2524335384368896\n",
      "Epoch 66 - Data Point 1 - Loss: 13.11085033416748\n",
      "Epoch 66 - Data Point 2 - Loss: 76.22370147705078\n",
      "Epoch 67 - Data Point 0 - Loss: 36.3402214050293\n",
      "Epoch 67 - Data Point 1 - Loss: 150.07264709472656\n",
      "Epoch 67 - Data Point 2 - Loss: 0.32547610998153687\n",
      "Epoch 68 - Data Point 0 - Loss: 1.2776827812194824\n",
      "Epoch 68 - Data Point 1 - Loss: 12.849363327026367\n",
      "Epoch 68 - Data Point 2 - Loss: 75.85279083251953\n",
      "Epoch 69 - Data Point 0 - Loss: 36.20531463623047\n",
      "Epoch 69 - Data Point 1 - Loss: 149.1868438720703\n",
      "Epoch 69 - Data Point 2 - Loss: 0.30171602964401245\n",
      "Epoch 70 - Data Point 0 - Loss: 1.303067922592163\n",
      "Epoch 70 - Data Point 1 - Loss: 12.59168815612793\n",
      "Epoch 70 - Data Point 2 - Loss: 75.48448944091797\n",
      "Epoch 71 - Data Point 0 - Loss: 36.07127380371094\n",
      "Epoch 71 - Data Point 1 - Loss: 148.3076629638672\n",
      "Epoch 71 - Data Point 2 - Loss: 0.27895811200141907\n",
      "Epoch 72 - Data Point 0 - Loss: 1.3285852670669556\n",
      "Epoch 72 - Data Point 1 - Loss: 12.337777137756348\n",
      "Epoch 72 - Data Point 2 - Loss: 75.11873626708984\n",
      "Epoch 73 - Data Point 0 - Loss: 35.93810272216797\n",
      "Epoch 73 - Data Point 1 - Loss: 147.43511962890625\n",
      "Epoch 73 - Data Point 2 - Loss: 0.25719210505485535\n",
      "Epoch 74 - Data Point 0 - Loss: 1.3542306423187256\n",
      "Epoch 74 - Data Point 1 - Loss: 12.087604522705078\n",
      "Epoch 74 - Data Point 2 - Loss: 74.75557708740234\n",
      "Epoch 75 - Data Point 0 - Loss: 35.80579376220703\n",
      "Epoch 75 - Data Point 1 - Loss: 146.56915283203125\n",
      "Epoch 75 - Data Point 2 - Loss: 0.23640374839305878\n",
      "Epoch 76 - Data Point 0 - Loss: 1.3800013065338135\n",
      "Epoch 76 - Data Point 1 - Loss: 11.841129302978516\n",
      "Epoch 76 - Data Point 2 - Loss: 74.39496612548828\n",
      "Epoch 77 - Data Point 0 - Loss: 35.674320220947266\n",
      "Epoch 77 - Data Point 1 - Loss: 145.709716796875\n",
      "Epoch 77 - Data Point 2 - Loss: 0.21657827496528625\n",
      "Epoch 78 - Data Point 0 - Loss: 1.405896782875061\n",
      "Epoch 78 - Data Point 1 - Loss: 11.59829044342041\n",
      "Epoch 78 - Data Point 2 - Loss: 74.03682708740234\n",
      "Epoch 79 - Data Point 0 - Loss: 35.54368591308594\n",
      "Epoch 79 - Data Point 1 - Loss: 144.8566436767578\n",
      "Epoch 79 - Data Point 2 - Loss: 0.1977057158946991\n",
      "Epoch 80 - Data Point 0 - Loss: 1.431913137435913\n",
      "Epoch 80 - Data Point 1 - Loss: 11.35905933380127\n",
      "Epoch 80 - Data Point 2 - Loss: 73.68118286132812\n",
      "Epoch 81 - Data Point 0 - Loss: 35.413883209228516\n",
      "Epoch 81 - Data Point 1 - Loss: 144.0098876953125\n",
      "Epoch 81 - Data Point 2 - Loss: 0.17977581918239594\n",
      "Epoch 82 - Data Point 0 - Loss: 1.4580481052398682\n",
      "Epoch 82 - Data Point 1 - Loss: 11.123392105102539\n",
      "Epoch 82 - Data Point 2 - Loss: 73.32803344726562\n",
      "Epoch 83 - Data Point 0 - Loss: 35.28493118286133\n",
      "Epoch 83 - Data Point 1 - Loss: 143.16958618164062\n",
      "Epoch 83 - Data Point 2 - Loss: 0.16277191042900085\n",
      "Epoch 84 - Data Point 0 - Loss: 1.4842987060546875\n",
      "Epoch 84 - Data Point 1 - Loss: 10.891257286071777\n",
      "Epoch 84 - Data Point 2 - Loss: 72.97732543945312\n",
      "Epoch 85 - Data Point 0 - Loss: 35.156776428222656\n",
      "Epoch 85 - Data Point 1 - Loss: 142.33551025390625\n",
      "Epoch 85 - Data Point 2 - Loss: 0.1466856300830841\n",
      "Epoch 86 - Data Point 0 - Loss: 1.5106598138809204\n",
      "Epoch 86 - Data Point 1 - Loss: 10.662623405456543\n",
      "Epoch 86 - Data Point 2 - Loss: 72.62907409667969\n",
      "Epoch 87 - Data Point 0 - Loss: 35.02945327758789\n",
      "Epoch 87 - Data Point 1 - Loss: 141.5077362060547\n",
      "Epoch 87 - Data Point 2 - Loss: 0.13150320947170258\n",
      "Epoch 88 - Data Point 0 - Loss: 1.5371311902999878\n",
      "Epoch 88 - Data Point 1 - Loss: 10.437438011169434\n",
      "Epoch 88 - Data Point 2 - Loss: 72.283203125\n",
      "Epoch 89 - Data Point 0 - Loss: 34.902931213378906\n",
      "Epoch 89 - Data Point 1 - Loss: 140.68603515625\n",
      "Epoch 89 - Data Point 2 - Loss: 0.11721332371234894\n",
      "Epoch 90 - Data Point 0 - Loss: 1.5637125968933105\n",
      "Epoch 90 - Data Point 1 - Loss: 10.215654373168945\n",
      "Epoch 90 - Data Point 2 - Loss: 71.93976593017578\n",
      "Epoch 91 - Data Point 0 - Loss: 34.77722930908203\n",
      "Epoch 91 - Data Point 1 - Loss: 139.8705291748047\n",
      "Epoch 91 - Data Point 2 - Loss: 0.10380657762289047\n",
      "Epoch 92 - Data Point 0 - Loss: 1.5903961658477783\n",
      "Epoch 92 - Data Point 1 - Loss: 9.997271537780762\n",
      "Epoch 92 - Data Point 2 - Loss: 71.59872436523438\n",
      "Epoch 93 - Data Point 0 - Loss: 34.65231704711914\n",
      "Epoch 93 - Data Point 1 - Loss: 139.0611572265625\n",
      "Epoch 93 - Data Point 2 - Loss: 0.09126798063516617\n",
      "Epoch 94 - Data Point 0 - Loss: 1.6171818971633911\n",
      "Epoch 94 - Data Point 1 - Loss: 9.782225608825684\n",
      "Epoch 94 - Data Point 2 - Loss: 71.260009765625\n",
      "Epoch 95 - Data Point 0 - Loss: 34.5281982421875\n",
      "Epoch 95 - Data Point 1 - Loss: 138.25772094726562\n",
      "Epoch 95 - Data Point 2 - Loss: 0.07958778738975525\n",
      "Epoch 96 - Data Point 0 - Loss: 1.6440701484680176\n",
      "Epoch 96 - Data Point 1 - Loss: 9.570470809936523\n",
      "Epoch 96 - Data Point 2 - Loss: 70.92364501953125\n",
      "Epoch 97 - Data Point 0 - Loss: 34.40486145019531\n",
      "Epoch 97 - Data Point 1 - Loss: 137.4602508544922\n",
      "Epoch 97 - Data Point 2 - Loss: 0.06875503063201904\n",
      "Epoch 98 - Data Point 0 - Loss: 1.6710543632507324\n",
      "Epoch 98 - Data Point 1 - Loss: 9.361984252929688\n",
      "Epoch 98 - Data Point 2 - Loss: 70.58960723876953\n",
      "Epoch 99 - Data Point 0 - Loss: 34.28231430053711\n",
      "Epoch 99 - Data Point 1 - Loss: 136.66873168945312\n",
      "Epoch 99 - Data Point 2 - Loss: 0.05875876545906067\n",
      "Epoch 100 - Data Point 0 - Loss: 1.6981345415115356\n",
      "Epoch 100 - Data Point 1 - Loss: 9.156733512878418\n",
      "Epoch 100 - Data Point 2 - Loss: 70.25787353515625\n",
      "Epoch 101 - Data Point 0 - Loss: 34.16053771972656\n",
      "Epoch 101 - Data Point 1 - Loss: 135.8831024169922\n",
      "Epoch 101 - Data Point 2 - Loss: 0.04958769679069519\n",
      "Epoch 102 - Data Point 0 - Loss: 1.7253059148788452\n",
      "Epoch 102 - Data Point 1 - Loss: 8.954684257507324\n",
      "Epoch 102 - Data Point 2 - Loss: 69.9284439086914\n",
      "Epoch 103 - Data Point 0 - Loss: 34.03953552246094\n",
      "Epoch 103 - Data Point 1 - Loss: 135.10328674316406\n",
      "Epoch 103 - Data Point 2 - Loss: 0.041231099516153336\n",
      "Epoch 104 - Data Point 0 - Loss: 1.7525678873062134\n",
      "Epoch 104 - Data Point 1 - Loss: 8.755794525146484\n",
      "Epoch 104 - Data Point 2 - Loss: 69.6012954711914\n",
      "Epoch 105 - Data Point 0 - Loss: 33.9193115234375\n",
      "Epoch 105 - Data Point 1 - Loss: 134.329345703125\n",
      "Epoch 105 - Data Point 2 - Loss: 0.0336776077747345\n",
      "Epoch 106 - Data Point 0 - Loss: 1.7799164056777954\n",
      "Epoch 106 - Data Point 1 - Loss: 8.560033798217773\n",
      "Epoch 106 - Data Point 2 - Loss: 69.2763900756836\n",
      "Epoch 107 - Data Point 0 - Loss: 33.799842834472656\n",
      "Epoch 107 - Data Point 1 - Loss: 133.56114196777344\n",
      "Epoch 107 - Data Point 2 - Loss: 0.02691650390625\n",
      "Epoch 108 - Data Point 0 - Loss: 1.8073508739471436\n",
      "Epoch 108 - Data Point 1 - Loss: 8.367361068725586\n",
      "Epoch 108 - Data Point 2 - Loss: 68.95370483398438\n",
      "Epoch 109 - Data Point 0 - Loss: 33.68110656738281\n",
      "Epoch 109 - Data Point 1 - Loss: 132.79849243164062\n",
      "Epoch 109 - Data Point 2 - Loss: 0.02093837969005108\n",
      "Epoch 110 - Data Point 0 - Loss: 1.8348712921142578\n",
      "Epoch 110 - Data Point 1 - Loss: 8.177736282348633\n",
      "Epoch 110 - Data Point 2 - Loss: 68.63325500488281\n",
      "Epoch 111 - Data Point 0 - Loss: 33.56313705444336\n",
      "Epoch 111 - Data Point 1 - Loss: 132.04161071777344\n",
      "Epoch 111 - Data Point 2 - Loss: 0.015731994062662125\n",
      "Epoch 112 - Data Point 0 - Loss: 1.8624694347381592\n",
      "Epoch 112 - Data Point 1 - Loss: 7.991149425506592\n",
      "Epoch 112 - Data Point 2 - Loss: 68.31502532958984\n",
      "Epoch 113 - Data Point 0 - Loss: 33.445919036865234\n",
      "Epoch 113 - Data Point 1 - Loss: 131.29031372070312\n",
      "Epoch 113 - Data Point 2 - Loss: 0.011287805624306202\n",
      "Epoch 114 - Data Point 0 - Loss: 1.8901457786560059\n",
      "Epoch 114 - Data Point 1 - Loss: 7.807559967041016\n",
      "Epoch 114 - Data Point 2 - Loss: 67.99899291992188\n",
      "Epoch 115 - Data Point 0 - Loss: 33.329437255859375\n",
      "Epoch 115 - Data Point 1 - Loss: 130.54464721679688\n",
      "Epoch 115 - Data Point 2 - Loss: 0.007594224996864796\n",
      "Epoch 116 - Data Point 0 - Loss: 1.9178993701934814\n",
      "Epoch 116 - Data Point 1 - Loss: 7.626917839050293\n",
      "Epoch 116 - Data Point 2 - Loss: 67.68510437011719\n",
      "Epoch 117 - Data Point 0 - Loss: 33.213687896728516\n",
      "Epoch 117 - Data Point 1 - Loss: 129.8043975830078\n",
      "Epoch 117 - Data Point 2 - Loss: 0.004642413929104805\n",
      "Epoch 118 - Data Point 0 - Loss: 1.945726990699768\n",
      "Epoch 118 - Data Point 1 - Loss: 7.449202060699463\n",
      "Epoch 118 - Data Point 2 - Loss: 67.37336730957031\n",
      "Epoch 119 - Data Point 0 - Loss: 33.09865951538086\n",
      "Epoch 119 - Data Point 1 - Loss: 129.06964111328125\n",
      "Epoch 119 - Data Point 2 - Loss: 0.0024216780439019203\n",
      "Epoch 120 - Data Point 0 - Loss: 1.973628282546997\n",
      "Epoch 120 - Data Point 1 - Loss: 7.274368762969971\n",
      "Epoch 120 - Data Point 2 - Loss: 67.06376647949219\n",
      "Epoch 121 - Data Point 0 - Loss: 32.98434829711914\n",
      "Epoch 121 - Data Point 1 - Loss: 128.34024047851562\n",
      "Epoch 121 - Data Point 2 - Loss: 0.0009226119145750999\n",
      "Epoch 122 - Data Point 0 - Loss: 2.0015981197357178\n",
      "Epoch 122 - Data Point 1 - Loss: 7.102407932281494\n",
      "Epoch 122 - Data Point 2 - Loss: 66.75631713867188\n",
      "Epoch 123 - Data Point 0 - Loss: 32.87077331542969\n",
      "Epoch 123 - Data Point 1 - Loss: 127.61637115478516\n",
      "Epoch 123 - Data Point 2 - Loss: 0.00013510302233044058\n",
      "Epoch 124 - Data Point 0 - Loss: 2.0296342372894287\n",
      "Epoch 124 - Data Point 1 - Loss: 6.933279991149902\n",
      "Epoch 124 - Data Point 2 - Loss: 66.45097351074219\n",
      "Epoch 125 - Data Point 0 - Loss: 32.75791931152344\n",
      "Epoch 125 - Data Point 1 - Loss: 126.8978042602539\n",
      "Epoch 125 - Data Point 2 - Loss: 4.9588794354349375e-05\n",
      "Epoch 126 - Data Point 0 - Loss: 2.0577361583709717\n",
      "Epoch 126 - Data Point 1 - Loss: 6.76694393157959\n",
      "Epoch 126 - Data Point 2 - Loss: 66.14769744873047\n",
      "Epoch 127 - Data Point 0 - Loss: 32.645748138427734\n",
      "Epoch 127 - Data Point 1 - Loss: 126.18448638916016\n",
      "Epoch 127 - Data Point 2 - Loss: 0.0006565545918419957\n",
      "Epoch 128 - Data Point 0 - Loss: 2.0859038829803467\n",
      "Epoch 128 - Data Point 1 - Loss: 6.60336446762085\n",
      "Epoch 128 - Data Point 2 - Loss: 65.84648895263672\n",
      "Epoch 129 - Data Point 0 - Loss: 32.53429412841797\n",
      "Epoch 129 - Data Point 1 - Loss: 125.4764175415039\n",
      "Epoch 129 - Data Point 2 - Loss: 0.00194639153778553\n",
      "Epoch 130 - Data Point 0 - Loss: 2.114131212234497\n",
      "Epoch 130 - Data Point 1 - Loss: 6.44252872467041\n",
      "Epoch 130 - Data Point 2 - Loss: 65.54735565185547\n",
      "Epoch 131 - Data Point 0 - Loss: 32.423526763916016\n",
      "Epoch 131 - Data Point 1 - Loss: 124.77354431152344\n",
      "Epoch 131 - Data Point 2 - Loss: 0.0039095887914299965\n",
      "Epoch 132 - Data Point 0 - Loss: 2.142418622970581\n",
      "Epoch 132 - Data Point 1 - Loss: 6.284399509429932\n",
      "Epoch 132 - Data Point 2 - Loss: 65.25028228759766\n",
      "Epoch 133 - Data Point 0 - Loss: 32.313472747802734\n",
      "Epoch 133 - Data Point 1 - Loss: 124.07595825195312\n",
      "Epoch 133 - Data Point 2 - Loss: 0.00653728237375617\n",
      "Epoch 134 - Data Point 0 - Loss: 2.170761823654175\n",
      "Epoch 134 - Data Point 1 - Loss: 6.1289448738098145\n",
      "Epoch 134 - Data Point 2 - Loss: 64.95523071289062\n",
      "Epoch 135 - Data Point 0 - Loss: 32.20409393310547\n",
      "Epoch 135 - Data Point 1 - Loss: 123.38346099853516\n",
      "Epoch 135 - Data Point 2 - Loss: 0.00982026569545269\n",
      "Epoch 136 - Data Point 0 - Loss: 2.1991610527038574\n",
      "Epoch 136 - Data Point 1 - Loss: 5.976130485534668\n",
      "Epoch 136 - Data Point 2 - Loss: 64.66216278076172\n",
      "Epoch 137 - Data Point 0 - Loss: 32.09540557861328\n",
      "Epoch 137 - Data Point 1 - Loss: 122.69603729248047\n",
      "Epoch 137 - Data Point 2 - Loss: 0.013749008066952229\n",
      "Epoch 138 - Data Point 0 - Loss: 2.227614164352417\n",
      "Epoch 138 - Data Point 1 - Loss: 5.825935363769531\n",
      "Epoch 138 - Data Point 2 - Loss: 64.37110900878906\n",
      "Epoch 139 - Data Point 0 - Loss: 31.987398147583008\n",
      "Epoch 139 - Data Point 1 - Loss: 122.01364135742188\n",
      "Epoch 139 - Data Point 2 - Loss: 0.018314778804779053\n",
      "Epoch 140 - Data Point 0 - Loss: 2.2561194896698\n",
      "Epoch 140 - Data Point 1 - Loss: 5.678320407867432\n",
      "Epoch 140 - Data Point 2 - Loss: 64.0820541381836\n",
      "Epoch 141 - Data Point 0 - Loss: 31.88006019592285\n",
      "Epoch 141 - Data Point 1 - Loss: 121.33626556396484\n",
      "Epoch 141 - Data Point 2 - Loss: 0.023508287966251373\n",
      "Epoch 142 - Data Point 0 - Loss: 2.284672260284424\n",
      "Epoch 142 - Data Point 1 - Loss: 5.533269882202148\n",
      "Epoch 142 - Data Point 2 - Loss: 63.79496383666992\n",
      "Epoch 143 - Data Point 0 - Loss: 31.773399353027344\n",
      "Epoch 143 - Data Point 1 - Loss: 120.66390991210938\n",
      "Epoch 143 - Data Point 2 - Loss: 0.029322434216737747\n",
      "Epoch 144 - Data Point 0 - Loss: 2.313276767730713\n",
      "Epoch 144 - Data Point 1 - Loss: 5.390729904174805\n",
      "Epoch 144 - Data Point 2 - Loss: 63.50979995727539\n",
      "Epoch 145 - Data Point 0 - Loss: 31.667394638061523\n",
      "Epoch 145 - Data Point 1 - Loss: 119.99639129638672\n",
      "Epoch 145 - Data Point 2 - Loss: 0.03574701026082039\n",
      "Epoch 146 - Data Point 0 - Loss: 2.3419265747070312\n",
      "Epoch 146 - Data Point 1 - Loss: 5.250690937042236\n",
      "Epoch 146 - Data Point 2 - Loss: 63.2265625\n",
      "Epoch 147 - Data Point 0 - Loss: 31.562042236328125\n",
      "Epoch 147 - Data Point 1 - Loss: 119.33377075195312\n",
      "Epoch 147 - Data Point 2 - Loss: 0.042773135006427765\n",
      "Epoch 148 - Data Point 0 - Loss: 2.3706204891204834\n",
      "Epoch 148 - Data Point 1 - Loss: 5.113123416900635\n",
      "Epoch 148 - Data Point 2 - Loss: 62.94527053833008\n",
      "Epoch 149 - Data Point 0 - Loss: 31.45735740661621\n",
      "Epoch 149 - Data Point 1 - Loss: 118.67599487304688\n",
      "Epoch 149 - Data Point 2 - Loss: 0.05039283633232117\n",
      "Epoch 150 - Data Point 0 - Loss: 2.3993561267852783\n",
      "Epoch 150 - Data Point 1 - Loss: 4.977999210357666\n",
      "Epoch 150 - Data Point 2 - Loss: 62.66588592529297\n",
      "Epoch 151 - Data Point 0 - Loss: 31.35331916809082\n",
      "Epoch 151 - Data Point 1 - Loss: 118.02306365966797\n",
      "Epoch 151 - Data Point 2 - Loss: 0.05859844386577606\n",
      "Epoch 152 - Data Point 0 - Loss: 2.4281325340270996\n",
      "Epoch 152 - Data Point 1 - Loss: 4.8452887535095215\n",
      "Epoch 152 - Data Point 2 - Loss: 62.388389587402344\n",
      "Epoch 153 - Data Point 0 - Loss: 31.249935150146484\n",
      "Epoch 153 - Data Point 1 - Loss: 117.37490844726562\n",
      "Epoch 153 - Data Point 2 - Loss: 0.06738011538982391\n",
      "Epoch 154 - Data Point 0 - Loss: 2.4569458961486816\n",
      "Epoch 154 - Data Point 1 - Loss: 4.714975357055664\n",
      "Epoch 154 - Data Point 2 - Loss: 62.11277770996094\n",
      "Epoch 155 - Data Point 0 - Loss: 31.147186279296875\n",
      "Epoch 155 - Data Point 1 - Loss: 116.73150634765625\n",
      "Epoch 155 - Data Point 2 - Loss: 0.07672923803329468\n",
      "Epoch 156 - Data Point 0 - Loss: 2.485795497894287\n",
      "Epoch 156 - Data Point 1 - Loss: 4.58702278137207\n",
      "Epoch 156 - Data Point 2 - Loss: 61.83906555175781\n",
      "Epoch 157 - Data Point 0 - Loss: 31.045089721679688\n",
      "Epoch 157 - Data Point 1 - Loss: 116.09280395507812\n",
      "Epoch 157 - Data Point 2 - Loss: 0.0866406038403511\n",
      "Epoch 158 - Data Point 0 - Loss: 2.5146842002868652\n",
      "Epoch 158 - Data Point 1 - Loss: 4.4613938331604\n",
      "Epoch 158 - Data Point 2 - Loss: 61.56716537475586\n",
      "Epoch 159 - Data Point 0 - Loss: 30.943601608276367\n",
      "Epoch 159 - Data Point 1 - Loss: 115.45870971679688\n",
      "Epoch 159 - Data Point 2 - Loss: 0.09710390120744705\n",
      "Epoch 160 - Data Point 0 - Loss: 2.543605327606201\n",
      "Epoch 160 - Data Point 1 - Loss: 4.338071346282959\n",
      "Epoch 160 - Data Point 2 - Loss: 61.29710006713867\n",
      "Epoch 161 - Data Point 0 - Loss: 30.84275245666504\n",
      "Epoch 161 - Data Point 1 - Loss: 114.82925415039062\n",
      "Epoch 161 - Data Point 2 - Loss: 0.10811145603656769\n",
      "Epoch 162 - Data Point 0 - Loss: 2.572558641433716\n",
      "Epoch 162 - Data Point 1 - Loss: 4.2170305252075195\n",
      "Epoch 162 - Data Point 2 - Loss: 61.02886962890625\n",
      "Epoch 163 - Data Point 0 - Loss: 30.742530822753906\n",
      "Epoch 163 - Data Point 1 - Loss: 114.20439147949219\n",
      "Epoch 163 - Data Point 2 - Loss: 0.11965707689523697\n",
      "Epoch 164 - Data Point 0 - Loss: 2.601544141769409\n",
      "Epoch 164 - Data Point 1 - Loss: 4.098236083984375\n",
      "Epoch 164 - Data Point 2 - Loss: 60.762428283691406\n",
      "Epoch 165 - Data Point 0 - Loss: 30.642927169799805\n",
      "Epoch 165 - Data Point 1 - Loss: 113.58406066894531\n",
      "Epoch 165 - Data Point 2 - Loss: 0.13172948360443115\n",
      "Epoch 166 - Data Point 0 - Loss: 2.6305551528930664\n",
      "Epoch 166 - Data Point 1 - Loss: 3.981679916381836\n",
      "Epoch 166 - Data Point 2 - Loss: 60.497802734375\n",
      "Epoch 167 - Data Point 0 - Loss: 30.5439395904541\n",
      "Epoch 167 - Data Point 1 - Loss: 112.96821594238281\n",
      "Epoch 167 - Data Point 2 - Loss: 0.14432398974895477\n",
      "Epoch 168 - Data Point 0 - Loss: 2.6595964431762695\n",
      "Epoch 168 - Data Point 1 - Loss: 3.8673183917999268\n",
      "Epoch 168 - Data Point 2 - Loss: 60.23495101928711\n",
      "Epoch 169 - Data Point 0 - Loss: 30.445552825927734\n",
      "Epoch 169 - Data Point 1 - Loss: 112.35689544677734\n",
      "Epoch 169 - Data Point 2 - Loss: 0.15743286907672882\n",
      "Epoch 170 - Data Point 0 - Loss: 2.6886651515960693\n",
      "Epoch 170 - Data Point 1 - Loss: 3.75512957572937\n",
      "Epoch 170 - Data Point 2 - Loss: 59.97385025024414\n",
      "Epoch 171 - Data Point 0 - Loss: 30.347776412963867\n",
      "Epoch 171 - Data Point 1 - Loss: 111.7499771118164\n",
      "Epoch 171 - Data Point 2 - Loss: 0.17104679346084595\n",
      "Epoch 172 - Data Point 0 - Loss: 2.71775484085083\n",
      "Epoch 172 - Data Point 1 - Loss: 3.6450998783111572\n",
      "Epoch 172 - Data Point 2 - Loss: 59.71451950073242\n",
      "Epoch 173 - Data Point 0 - Loss: 30.250608444213867\n",
      "Epoch 173 - Data Point 1 - Loss: 111.14743041992188\n",
      "Epoch 173 - Data Point 2 - Loss: 0.18515869975090027\n",
      "Epoch 174 - Data Point 0 - Loss: 2.7468676567077637\n",
      "Epoch 174 - Data Point 1 - Loss: 3.537196159362793\n",
      "Epoch 174 - Data Point 2 - Loss: 59.456932067871094\n",
      "Epoch 175 - Data Point 0 - Loss: 30.154041290283203\n",
      "Epoch 175 - Data Point 1 - Loss: 110.54933166503906\n",
      "Epoch 175 - Data Point 2 - Loss: 0.19976170361042023\n",
      "Epoch 176 - Data Point 0 - Loss: 2.776000499725342\n",
      "Epoch 176 - Data Point 1 - Loss: 3.431399345397949\n",
      "Epoch 176 - Data Point 2 - Loss: 59.201087951660156\n",
      "Epoch 177 - Data Point 0 - Loss: 30.05805778503418\n",
      "Epoch 177 - Data Point 1 - Loss: 109.95552062988281\n",
      "Epoch 177 - Data Point 2 - Loss: 0.21484729647636414\n",
      "Epoch 178 - Data Point 0 - Loss: 2.8051528930664062\n",
      "Epoch 178 - Data Point 1 - Loss: 3.3276827335357666\n",
      "Epoch 178 - Data Point 2 - Loss: 58.94696044921875\n",
      "Epoch 179 - Data Point 0 - Loss: 29.96268081665039\n",
      "Epoch 179 - Data Point 1 - Loss: 109.36605834960938\n",
      "Epoch 179 - Data Point 2 - Loss: 0.23041146993637085\n",
      "Epoch 180 - Data Point 0 - Loss: 2.8343257904052734\n",
      "Epoch 180 - Data Point 1 - Loss: 3.226015090942383\n",
      "Epoch 180 - Data Point 2 - Loss: 58.69451904296875\n",
      "Epoch 181 - Data Point 0 - Loss: 29.867874145507812\n",
      "Epoch 181 - Data Point 1 - Loss: 108.78080749511719\n",
      "Epoch 181 - Data Point 2 - Loss: 0.24644409120082855\n",
      "Epoch 182 - Data Point 0 - Loss: 2.863513946533203\n",
      "Epoch 182 - Data Point 1 - Loss: 3.126377582550049\n",
      "Epoch 182 - Data Point 2 - Loss: 58.44377899169922\n",
      "Epoch 183 - Data Point 0 - Loss: 29.773658752441406\n",
      "Epoch 183 - Data Point 1 - Loss: 108.19984436035156\n",
      "Epoch 183 - Data Point 2 - Loss: 0.26293960213661194\n",
      "Epoch 184 - Data Point 0 - Loss: 2.892717123031616\n",
      "Epoch 184 - Data Point 1 - Loss: 3.0287508964538574\n",
      "Epoch 184 - Data Point 2 - Loss: 58.19470977783203\n",
      "Epoch 185 - Data Point 0 - Loss: 29.680017471313477\n",
      "Epoch 185 - Data Point 1 - Loss: 107.62301635742188\n",
      "Epoch 185 - Data Point 2 - Loss: 0.2798897325992584\n",
      "Epoch 186 - Data Point 0 - Loss: 2.9219348430633545\n",
      "Epoch 186 - Data Point 1 - Loss: 2.9331040382385254\n",
      "Epoch 186 - Data Point 2 - Loss: 57.94730758666992\n",
      "Epoch 187 - Data Point 0 - Loss: 29.586956024169922\n",
      "Epoch 187 - Data Point 1 - Loss: 107.05038452148438\n",
      "Epoch 187 - Data Point 2 - Loss: 0.29728710651397705\n",
      "Epoch 188 - Data Point 0 - Loss: 2.9511616230010986\n",
      "Epoch 188 - Data Point 1 - Loss: 2.8394272327423096\n",
      "Epoch 188 - Data Point 2 - Loss: 57.70157241821289\n",
      "Epoch 189 - Data Point 0 - Loss: 29.494462966918945\n",
      "Epoch 189 - Data Point 1 - Loss: 106.48192596435547\n",
      "Epoch 189 - Data Point 2 - Loss: 0.31512653827667236\n",
      "Epoch 190 - Data Point 0 - Loss: 2.980400562286377\n",
      "Epoch 190 - Data Point 1 - Loss: 2.747687339782715\n",
      "Epoch 190 - Data Point 2 - Loss: 57.45747756958008\n",
      "Epoch 191 - Data Point 0 - Loss: 29.402536392211914\n",
      "Epoch 191 - Data Point 1 - Loss: 105.91754913330078\n",
      "Epoch 191 - Data Point 2 - Loss: 0.33339980244636536\n",
      "Epoch 192 - Data Point 0 - Loss: 3.0096497535705566\n",
      "Epoch 192 - Data Point 1 - Loss: 2.657862663269043\n",
      "Epoch 192 - Data Point 2 - Loss: 57.215023040771484\n",
      "Epoch 193 - Data Point 0 - Loss: 29.311180114746094\n",
      "Epoch 193 - Data Point 1 - Loss: 105.35726928710938\n",
      "Epoch 193 - Data Point 2 - Loss: 0.35210320353507996\n",
      "Epoch 194 - Data Point 0 - Loss: 3.0389068126678467\n",
      "Epoch 194 - Data Point 1 - Loss: 2.569927453994751\n",
      "Epoch 194 - Data Point 2 - Loss: 56.97416687011719\n",
      "Epoch 195 - Data Point 0 - Loss: 29.220373153686523\n",
      "Epoch 195 - Data Point 1 - Loss: 104.80096435546875\n",
      "Epoch 195 - Data Point 2 - Loss: 0.3712274730205536\n",
      "Epoch 196 - Data Point 0 - Loss: 3.068171977996826\n",
      "Epoch 196 - Data Point 1 - Loss: 2.4838600158691406\n",
      "Epoch 196 - Data Point 2 - Loss: 56.73491287231445\n",
      "Epoch 197 - Data Point 0 - Loss: 29.13011360168457\n",
      "Epoch 197 - Data Point 1 - Loss: 104.24864196777344\n",
      "Epoch 197 - Data Point 2 - Loss: 0.39076685905456543\n",
      "Epoch 198 - Data Point 0 - Loss: 3.097444772720337\n",
      "Epoch 198 - Data Point 1 - Loss: 2.3996403217315674\n",
      "Epoch 198 - Data Point 2 - Loss: 56.49724197387695\n",
      "Epoch 199 - Data Point 0 - Loss: 29.0404109954834\n",
      "Epoch 199 - Data Point 1 - Loss: 103.7003173828125\n",
      "Epoch 199 - Data Point 2 - Loss: 0.4107156991958618\n",
      "Epoch 200 - Data Point 0 - Loss: 3.1267197132110596\n",
      "Epoch 200 - Data Point 1 - Loss: 2.317248582839966\n",
      "Epoch 200 - Data Point 2 - Loss: 56.26115798950195\n",
      "Epoch 201 - Data Point 0 - Loss: 28.951255798339844\n",
      "Epoch 201 - Data Point 1 - Loss: 103.15596008300781\n",
      "Epoch 201 - Data Point 2 - Loss: 0.43106719851493835\n",
      "Epoch 202 - Data Point 0 - Loss: 3.155998706817627\n",
      "Epoch 202 - Data Point 1 - Loss: 2.236660957336426\n",
      "Epoch 202 - Data Point 2 - Loss: 56.026641845703125\n",
      "Epoch 203 - Data Point 0 - Loss: 28.86264419555664\n",
      "Epoch 203 - Data Point 1 - Loss: 102.61547088623047\n",
      "Epoch 203 - Data Point 2 - Loss: 0.45181208848953247\n",
      "Epoch 204 - Data Point 0 - Loss: 3.1852779388427734\n",
      "Epoch 204 - Data Point 1 - Loss: 2.157862424850464\n",
      "Epoch 204 - Data Point 2 - Loss: 55.79368209838867\n",
      "Epoch 205 - Data Point 0 - Loss: 28.774566650390625\n",
      "Epoch 205 - Data Point 1 - Loss: 102.0788345336914\n",
      "Epoch 205 - Data Point 2 - Loss: 0.47294872999191284\n",
      "Epoch 206 - Data Point 0 - Loss: 3.214561700820923\n",
      "Epoch 206 - Data Point 1 - Loss: 2.0808181762695312\n",
      "Epoch 206 - Data Point 2 - Loss: 55.562252044677734\n",
      "Epoch 207 - Data Point 0 - Loss: 28.687021255493164\n",
      "Epoch 207 - Data Point 1 - Loss: 101.54603576660156\n",
      "Epoch 207 - Data Point 2 - Loss: 0.4944652318954468\n",
      "Epoch 208 - Data Point 0 - Loss: 3.2438409328460693\n",
      "Epoch 208 - Data Point 1 - Loss: 2.005526304244995\n",
      "Epoch 208 - Data Point 2 - Loss: 55.332393646240234\n",
      "Epoch 209 - Data Point 0 - Loss: 28.60002899169922\n",
      "Epoch 209 - Data Point 1 - Loss: 101.01715087890625\n",
      "Epoch 209 - Data Point 2 - Loss: 0.5163602828979492\n",
      "Epoch 210 - Data Point 0 - Loss: 3.273117780685425\n",
      "Epoch 210 - Data Point 1 - Loss: 1.9319578409194946\n",
      "Epoch 210 - Data Point 2 - Loss: 55.104042053222656\n",
      "Epoch 211 - Data Point 0 - Loss: 28.5135440826416\n",
      "Epoch 211 - Data Point 1 - Loss: 100.49201202392578\n",
      "Epoch 211 - Data Point 2 - Loss: 0.5386289358139038\n",
      "Epoch 212 - Data Point 0 - Loss: 3.3023931980133057\n",
      "Epoch 212 - Data Point 1 - Loss: 1.8600832223892212\n",
      "Epoch 212 - Data Point 2 - Loss: 54.877193450927734\n",
      "Epoch 213 - Data Point 0 - Loss: 28.427597045898438\n",
      "Epoch 213 - Data Point 1 - Loss: 99.97061157226562\n",
      "Epoch 213 - Data Point 2 - Loss: 0.5612589716911316\n",
      "Epoch 214 - Data Point 0 - Loss: 3.3316633701324463\n",
      "Epoch 214 - Data Point 1 - Loss: 1.7898938655853271\n",
      "Epoch 214 - Data Point 2 - Loss: 54.651859283447266\n",
      "Epoch 215 - Data Point 0 - Loss: 28.342172622680664\n",
      "Epoch 215 - Data Point 1 - Loss: 99.45295715332031\n",
      "Epoch 215 - Data Point 2 - Loss: 0.5842483043670654\n",
      "Epoch 216 - Data Point 0 - Loss: 3.3609273433685303\n",
      "Epoch 216 - Data Point 1 - Loss: 1.721369743347168\n",
      "Epoch 216 - Data Point 2 - Loss: 54.42802047729492\n",
      "Epoch 217 - Data Point 0 - Loss: 28.257259368896484\n",
      "Epoch 217 - Data Point 1 - Loss: 98.93900299072266\n",
      "Epoch 217 - Data Point 2 - Loss: 0.6075949668884277\n",
      "Epoch 218 - Data Point 0 - Loss: 3.390188217163086\n",
      "Epoch 218 - Data Point 1 - Loss: 1.6544779539108276\n",
      "Epoch 218 - Data Point 2 - Loss: 54.20563507080078\n",
      "Epoch 219 - Data Point 0 - Loss: 28.172861099243164\n",
      "Epoch 219 - Data Point 1 - Loss: 98.4287109375\n",
      "Epoch 219 - Data Point 2 - Loss: 0.6312853693962097\n",
      "Epoch 220 - Data Point 0 - Loss: 3.4194366931915283\n",
      "Epoch 220 - Data Point 1 - Loss: 1.5892165899276733\n",
      "Epoch 220 - Data Point 2 - Loss: 53.984745025634766\n",
      "Epoch 221 - Data Point 0 - Loss: 28.088970184326172\n",
      "Epoch 221 - Data Point 1 - Loss: 97.92207336425781\n",
      "Epoch 221 - Data Point 2 - Loss: 0.6553191542625427\n",
      "Epoch 222 - Data Point 0 - Loss: 3.448678731918335\n",
      "Epoch 222 - Data Point 1 - Loss: 1.525552749633789\n",
      "Epoch 222 - Data Point 2 - Loss: 53.765296936035156\n",
      "Epoch 223 - Data Point 0 - Loss: 28.005599975585938\n",
      "Epoch 223 - Data Point 1 - Loss: 97.41905975341797\n",
      "Epoch 223 - Data Point 2 - Loss: 0.6796887516975403\n",
      "Epoch 224 - Data Point 0 - Loss: 3.4779112339019775\n",
      "Epoch 224 - Data Point 1 - Loss: 1.4634747505187988\n",
      "Epoch 224 - Data Point 2 - Loss: 53.54730224609375\n",
      "Epoch 225 - Data Point 0 - Loss: 27.92272186279297\n",
      "Epoch 225 - Data Point 1 - Loss: 96.91961669921875\n",
      "Epoch 225 - Data Point 2 - Loss: 0.7043895125389099\n",
      "Epoch 226 - Data Point 0 - Loss: 3.5071330070495605\n",
      "Epoch 226 - Data Point 1 - Loss: 1.402957797050476\n",
      "Epoch 226 - Data Point 2 - Loss: 53.33073806762695\n",
      "Epoch 227 - Data Point 0 - Loss: 27.840343475341797\n",
      "Epoch 227 - Data Point 1 - Loss: 96.4237060546875\n",
      "Epoch 227 - Data Point 2 - Loss: 0.7294138669967651\n",
      "Epoch 228 - Data Point 0 - Loss: 3.536341428756714\n",
      "Epoch 228 - Data Point 1 - Loss: 1.343988299369812\n",
      "Epoch 228 - Data Point 2 - Loss: 53.1156005859375\n",
      "Epoch 229 - Data Point 0 - Loss: 27.758466720581055\n",
      "Epoch 229 - Data Point 1 - Loss: 95.93135833740234\n",
      "Epoch 229 - Data Point 2 - Loss: 0.7547574043273926\n",
      "Epoch 230 - Data Point 0 - Loss: 3.5655362606048584\n",
      "Epoch 230 - Data Point 1 - Loss: 1.2865471839904785\n",
      "Epoch 230 - Data Point 2 - Loss: 52.90187454223633\n",
      "Epoch 231 - Data Point 0 - Loss: 27.67708396911621\n",
      "Epoch 231 - Data Point 1 - Loss: 95.44248962402344\n",
      "Epoch 231 - Data Point 2 - Loss: 0.7804157137870789\n",
      "Epoch 232 - Data Point 0 - Loss: 3.5947179794311523\n",
      "Epoch 232 - Data Point 1 - Loss: 1.2306134700775146\n",
      "Epoch 232 - Data Point 2 - Loss: 52.68955993652344\n",
      "Epoch 233 - Data Point 0 - Loss: 27.596195220947266\n",
      "Epoch 233 - Data Point 1 - Loss: 94.95710754394531\n",
      "Epoch 233 - Data Point 2 - Loss: 0.8063812851905823\n",
      "Epoch 234 - Data Point 0 - Loss: 3.6238834857940674\n",
      "Epoch 234 - Data Point 1 - Loss: 1.1761698722839355\n",
      "Epoch 234 - Data Point 2 - Loss: 52.47864532470703\n",
      "Epoch 235 - Data Point 0 - Loss: 27.515790939331055\n",
      "Epoch 235 - Data Point 1 - Loss: 94.47515869140625\n",
      "Epoch 235 - Data Point 2 - Loss: 0.8326517343521118\n",
      "Epoch 236 - Data Point 0 - Loss: 3.6530346870422363\n",
      "Epoch 236 - Data Point 1 - Loss: 1.1231975555419922\n",
      "Epoch 236 - Data Point 2 - Loss: 52.269100189208984\n",
      "Epoch 237 - Data Point 0 - Loss: 27.435869216918945\n",
      "Epoch 237 - Data Point 1 - Loss: 93.99664306640625\n",
      "Epoch 237 - Data Point 2 - Loss: 0.8592230081558228\n",
      "Epoch 238 - Data Point 0 - Loss: 3.6821672916412354\n",
      "Epoch 238 - Data Point 1 - Loss: 1.071677803993225\n",
      "Epoch 238 - Data Point 2 - Loss: 52.06093215942383\n",
      "Epoch 239 - Data Point 0 - Loss: 27.356426239013672\n",
      "Epoch 239 - Data Point 1 - Loss: 93.52151489257812\n",
      "Epoch 239 - Data Point 2 - Loss: 0.8860823512077332\n",
      "Epoch 240 - Data Point 0 - Loss: 3.7112812995910645\n",
      "Epoch 240 - Data Point 1 - Loss: 1.0215988159179688\n",
      "Epoch 240 - Data Point 2 - Loss: 51.8541374206543\n",
      "Epoch 241 - Data Point 0 - Loss: 27.277467727661133\n",
      "Epoch 241 - Data Point 1 - Loss: 93.04976654052734\n",
      "Epoch 241 - Data Point 2 - Loss: 0.9132347702980042\n",
      "Epoch 242 - Data Point 0 - Loss: 3.7403781414031982\n",
      "Epoch 242 - Data Point 1 - Loss: 0.9729334712028503\n",
      "Epoch 242 - Data Point 2 - Loss: 51.6486701965332\n",
      "Epoch 243 - Data Point 0 - Loss: 27.198972702026367\n",
      "Epoch 243 - Data Point 1 - Loss: 92.5813217163086\n",
      "Epoch 243 - Data Point 2 - Loss: 0.9406692385673523\n",
      "Epoch 244 - Data Point 0 - Loss: 3.7694544792175293\n",
      "Epoch 244 - Data Point 1 - Loss: 0.9256703853607178\n",
      "Epoch 244 - Data Point 2 - Loss: 51.44455337524414\n",
      "Epoch 245 - Data Point 0 - Loss: 27.12095069885254\n",
      "Epoch 245 - Data Point 1 - Loss: 92.11619567871094\n",
      "Epoch 245 - Data Point 2 - Loss: 0.9683784246444702\n",
      "Epoch 246 - Data Point 0 - Loss: 3.798509359359741\n",
      "Epoch 246 - Data Point 1 - Loss: 0.8797942996025085\n",
      "Epoch 246 - Data Point 2 - Loss: 51.241783142089844\n",
      "Epoch 247 - Data Point 0 - Loss: 27.043399810791016\n",
      "Epoch 247 - Data Point 1 - Loss: 91.65438079833984\n",
      "Epoch 247 - Data Point 2 - Loss: 0.9963603019714355\n",
      "Epoch 248 - Data Point 0 - Loss: 3.8275415897369385\n",
      "Epoch 248 - Data Point 1 - Loss: 0.8352870941162109\n",
      "Epoch 248 - Data Point 2 - Loss: 51.040348052978516\n",
      "Epoch 249 - Data Point 0 - Loss: 26.96631622314453\n",
      "Epoch 249 - Data Point 1 - Loss: 91.19583892822266\n",
      "Epoch 249 - Data Point 2 - Loss: 1.0246132612228394\n",
      "Epoch 250 - Data Point 0 - Loss: 3.8565514087677\n",
      "Epoch 250 - Data Point 1 - Loss: 0.7921268939971924\n",
      "Epoch 250 - Data Point 2 - Loss: 50.840206146240234\n",
      "Epoch 251 - Data Point 0 - Loss: 26.88968849182129\n",
      "Epoch 251 - Data Point 1 - Loss: 90.74051666259766\n",
      "Epoch 251 - Data Point 2 - Loss: 1.0531281232833862\n",
      "Epoch 252 - Data Point 0 - Loss: 3.8855373859405518\n",
      "Epoch 252 - Data Point 1 - Loss: 0.7503032088279724\n",
      "Epoch 252 - Data Point 2 - Loss: 50.641380310058594\n",
      "Epoch 253 - Data Point 0 - Loss: 26.813520431518555\n",
      "Epoch 253 - Data Point 1 - Loss: 90.28838348388672\n",
      "Epoch 253 - Data Point 2 - Loss: 1.0819014310836792\n",
      "Epoch 254 - Data Point 0 - Loss: 3.914499521255493\n",
      "Epoch 254 - Data Point 1 - Loss: 0.709795355796814\n",
      "Epoch 254 - Data Point 2 - Loss: 50.44384002685547\n",
      "Epoch 255 - Data Point 0 - Loss: 26.737810134887695\n",
      "Epoch 255 - Data Point 1 - Loss: 89.8394775390625\n",
      "Epoch 255 - Data Point 2 - Loss: 1.1109298467636108\n",
      "Epoch 256 - Data Point 0 - Loss: 3.9434359073638916\n",
      "Epoch 256 - Data Point 1 - Loss: 0.670590341091156\n",
      "Epoch 256 - Data Point 2 - Loss: 50.247589111328125\n",
      "Epoch 257 - Data Point 0 - Loss: 26.66255760192871\n",
      "Epoch 257 - Data Point 1 - Loss: 89.39370727539062\n",
      "Epoch 257 - Data Point 2 - Loss: 1.1402060985565186\n",
      "Epoch 258 - Data Point 0 - Loss: 3.9723455905914307\n",
      "Epoch 258 - Data Point 1 - Loss: 0.6326689720153809\n",
      "Epoch 258 - Data Point 2 - Loss: 50.0526123046875\n",
      "Epoch 259 - Data Point 0 - Loss: 26.587736129760742\n",
      "Epoch 259 - Data Point 1 - Loss: 88.95105743408203\n",
      "Epoch 259 - Data Point 2 - Loss: 1.1697227954864502\n",
      "Epoch 260 - Data Point 0 - Loss: 4.001226425170898\n",
      "Epoch 260 - Data Point 1 - Loss: 0.5960198044776917\n",
      "Epoch 260 - Data Point 2 - Loss: 49.858917236328125\n",
      "Epoch 261 - Data Point 0 - Loss: 26.513376235961914\n",
      "Epoch 261 - Data Point 1 - Loss: 88.5115737915039\n",
      "Epoch 261 - Data Point 2 - Loss: 1.199483036994934\n",
      "Epoch 262 - Data Point 0 - Loss: 4.0300798416137695\n",
      "Epoch 262 - Data Point 1 - Loss: 0.5606240034103394\n",
      "Epoch 262 - Data Point 2 - Loss: 49.666473388671875\n",
      "Epoch 263 - Data Point 0 - Loss: 26.43946075439453\n",
      "Epoch 263 - Data Point 1 - Loss: 88.07511138916016\n",
      "Epoch 263 - Data Point 2 - Loss: 1.2294775247573853\n",
      "Epoch 264 - Data Point 0 - Loss: 4.058907508850098\n",
      "Epoch 264 - Data Point 1 - Loss: 0.5264624953269958\n",
      "Epoch 264 - Data Point 2 - Loss: 49.47526931762695\n",
      "Epoch 265 - Data Point 0 - Loss: 26.36597442626953\n",
      "Epoch 265 - Data Point 1 - Loss: 87.64178466796875\n",
      "Epoch 265 - Data Point 2 - Loss: 1.2597053050994873\n",
      "Epoch 266 - Data Point 0 - Loss: 4.087701320648193\n",
      "Epoch 266 - Data Point 1 - Loss: 0.4935261607170105\n",
      "Epoch 266 - Data Point 2 - Loss: 49.285308837890625\n",
      "Epoch 267 - Data Point 0 - Loss: 26.29292869567871\n",
      "Epoch 267 - Data Point 1 - Loss: 87.21146392822266\n",
      "Epoch 267 - Data Point 2 - Loss: 1.2901616096496582\n",
      "Epoch 268 - Data Point 0 - Loss: 4.116469860076904\n",
      "Epoch 268 - Data Point 1 - Loss: 0.4617936313152313\n",
      "Epoch 268 - Data Point 2 - Loss: 49.09656524658203\n",
      "Epoch 269 - Data Point 0 - Loss: 26.220317840576172\n",
      "Epoch 269 - Data Point 1 - Loss: 86.78414154052734\n",
      "Epoch 269 - Data Point 2 - Loss: 1.3208370208740234\n",
      "Epoch 270 - Data Point 0 - Loss: 4.145205020904541\n",
      "Epoch 270 - Data Point 1 - Loss: 0.4312538206577301\n",
      "Epoch 270 - Data Point 2 - Loss: 48.909053802490234\n",
      "Epoch 271 - Data Point 0 - Loss: 26.148136138916016\n",
      "Epoch 271 - Data Point 1 - Loss: 86.35981750488281\n",
      "Epoch 271 - Data Point 2 - Loss: 1.3517264127731323\n",
      "Epoch 272 - Data Point 0 - Loss: 4.173906326293945\n",
      "Epoch 272 - Data Point 1 - Loss: 0.40189412236213684\n",
      "Epoch 272 - Data Point 2 - Loss: 48.72277069091797\n",
      "Epoch 273 - Data Point 0 - Loss: 26.076387405395508\n",
      "Epoch 273 - Data Point 1 - Loss: 85.93851470947266\n",
      "Epoch 273 - Data Point 2 - Loss: 1.382836103439331\n",
      "Epoch 274 - Data Point 0 - Loss: 4.202576160430908\n",
      "Epoch 274 - Data Point 1 - Loss: 0.3736940920352936\n",
      "Epoch 274 - Data Point 2 - Loss: 48.53766632080078\n",
      "Epoch 275 - Data Point 0 - Loss: 26.005062103271484\n",
      "Epoch 275 - Data Point 1 - Loss: 85.52008819580078\n",
      "Epoch 275 - Data Point 2 - Loss: 1.4141522645950317\n",
      "Epoch 276 - Data Point 0 - Loss: 4.23121452331543\n",
      "Epoch 276 - Data Point 1 - Loss: 0.34664103388786316\n",
      "Epoch 276 - Data Point 2 - Loss: 48.35376739501953\n",
      "Epoch 277 - Data Point 0 - Loss: 25.934160232543945\n",
      "Epoch 277 - Data Point 1 - Loss: 85.10460662841797\n",
      "Epoch 277 - Data Point 2 - Loss: 1.4456698894500732\n",
      "Epoch 278 - Data Point 0 - Loss: 4.25981330871582\n",
      "Epoch 278 - Data Point 1 - Loss: 0.32072368264198303\n",
      "Epoch 278 - Data Point 2 - Loss: 48.17106628417969\n",
      "Epoch 279 - Data Point 0 - Loss: 25.863679885864258\n",
      "Epoch 279 - Data Point 1 - Loss: 84.69207000732422\n",
      "Epoch 279 - Data Point 2 - Loss: 1.477393627166748\n",
      "Epoch 280 - Data Point 0 - Loss: 4.288381576538086\n",
      "Epoch 280 - Data Point 1 - Loss: 0.2959221601486206\n",
      "Epoch 280 - Data Point 2 - Loss: 47.989524841308594\n",
      "Epoch 281 - Data Point 0 - Loss: 25.793611526489258\n",
      "Epoch 281 - Data Point 1 - Loss: 84.28238677978516\n",
      "Epoch 281 - Data Point 2 - Loss: 1.509313941001892\n",
      "Epoch 282 - Data Point 0 - Loss: 4.31691312789917\n",
      "Epoch 282 - Data Point 1 - Loss: 0.2722255289554596\n",
      "Epoch 282 - Data Point 2 - Loss: 47.80915832519531\n",
      "Epoch 283 - Data Point 0 - Loss: 25.723960876464844\n",
      "Epoch 283 - Data Point 1 - Loss: 83.87554931640625\n",
      "Epoch 283 - Data Point 2 - Loss: 1.541426181793213\n",
      "Epoch 284 - Data Point 0 - Loss: 4.345408916473389\n",
      "Epoch 284 - Data Point 1 - Loss: 0.24961867928504944\n",
      "Epoch 284 - Data Point 2 - Loss: 47.629966735839844\n",
      "Epoch 285 - Data Point 0 - Loss: 25.654722213745117\n",
      "Epoch 285 - Data Point 1 - Loss: 83.4715576171875\n",
      "Epoch 285 - Data Point 2 - Loss: 1.5737258195877075\n",
      "Epoch 286 - Data Point 0 - Loss: 4.373864650726318\n",
      "Epoch 286 - Data Point 1 - Loss: 0.22809001803398132\n",
      "Epoch 286 - Data Point 2 - Loss: 47.451927185058594\n",
      "Epoch 287 - Data Point 0 - Loss: 25.58589744567871\n",
      "Epoch 287 - Data Point 1 - Loss: 83.07038879394531\n",
      "Epoch 287 - Data Point 2 - Loss: 1.6062079668045044\n",
      "Epoch 288 - Data Point 0 - Loss: 4.402284622192383\n",
      "Epoch 288 - Data Point 1 - Loss: 0.2076241821050644\n",
      "Epoch 288 - Data Point 2 - Loss: 47.2750358581543\n",
      "Epoch 289 - Data Point 0 - Loss: 25.51747703552246\n",
      "Epoch 289 - Data Point 1 - Loss: 82.67204284667969\n",
      "Epoch 289 - Data Point 2 - Loss: 1.6388754844665527\n",
      "Epoch 290 - Data Point 0 - Loss: 4.430662631988525\n",
      "Epoch 290 - Data Point 1 - Loss: 0.18820704519748688\n",
      "Epoch 290 - Data Point 2 - Loss: 47.09926223754883\n",
      "Epoch 291 - Data Point 0 - Loss: 25.449460983276367\n",
      "Epoch 291 - Data Point 1 - Loss: 82.27645111083984\n",
      "Epoch 291 - Data Point 2 - Loss: 1.671721339225769\n",
      "Epoch 292 - Data Point 0 - Loss: 4.459005355834961\n",
      "Epoch 292 - Data Point 1 - Loss: 0.16982391476631165\n",
      "Epoch 292 - Data Point 2 - Loss: 46.92462158203125\n",
      "Epoch 293 - Data Point 0 - Loss: 25.381839752197266\n",
      "Epoch 293 - Data Point 1 - Loss: 81.8835678100586\n",
      "Epoch 293 - Data Point 2 - Loss: 1.7047362327575684\n",
      "Epoch 294 - Data Point 0 - Loss: 4.487308025360107\n",
      "Epoch 294 - Data Point 1 - Loss: 0.1524631232023239\n",
      "Epoch 294 - Data Point 2 - Loss: 46.75111389160156\n",
      "Epoch 295 - Data Point 0 - Loss: 25.31462860107422\n",
      "Epoch 295 - Data Point 1 - Loss: 81.49345397949219\n",
      "Epoch 295 - Data Point 2 - Loss: 1.73792564868927\n",
      "Epoch 296 - Data Point 0 - Loss: 4.515570163726807\n",
      "Epoch 296 - Data Point 1 - Loss: 0.13611064851284027\n",
      "Epoch 296 - Data Point 2 - Loss: 46.57870864868164\n",
      "Epoch 297 - Data Point 0 - Loss: 25.247802734375\n",
      "Epoch 297 - Data Point 1 - Loss: 81.10601806640625\n",
      "Epoch 297 - Data Point 2 - Loss: 1.7712750434875488\n",
      "Epoch 298 - Data Point 0 - Loss: 4.543789386749268\n",
      "Epoch 298 - Data Point 1 - Loss: 0.12075547873973846\n",
      "Epoch 298 - Data Point 2 - Loss: 46.407413482666016\n",
      "Epoch 299 - Data Point 0 - Loss: 25.181373596191406\n",
      "Epoch 299 - Data Point 1 - Loss: 80.72132110595703\n",
      "Epoch 299 - Data Point 2 - Loss: 1.804795265197754\n",
      "when x = tensor([1., 3.]), y = tensor([3.1382], grad_fn=<SqueezeBackward4>)\n",
      "when x = tensor([2., 6.]), y = tensor([6.2764], grad_fn=<SqueezeBackward4>)\n",
      "when x = tensor([3., 9.]), y = tensor([9.4146], grad_fn=<SqueezeBackward4>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9fc281e370>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2,1,bias=False)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "\n",
    "net.fc1.weight = torch.nn.Parameter(torch.tensor([[1., -1.]], requires_grad=True))\n",
    "\n",
    "print(list(net.parameters()))\n",
    "\n",
    "#input = torch.randn(1,2)\n",
    "#out = net(input)\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "#def criterion(out, label):\n",
    "#    return ((label - out)**2).mean()\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.5) # Not changing the initial lr\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.005)\n",
    "\n",
    "\n",
    "data = torch.tensor([[1.,3.], [2.,6.], [3.,9.]], dtype=torch.float)\n",
    "target = torch.tensor([[1.],[5.],[13.]], dtype=torch.float)\n",
    "hist2 = []\n",
    "\n",
    "\n",
    "############# SGD based update ##############\n",
    "      \n",
    "for epoch in range(300):\n",
    "    for i, current_data in enumerate(data):  \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(data[i]) \n",
    "        loss = criterion(outputs, target[i])  \n",
    "        loss.backward()\n",
    "        hist2.append(loss.detach())\n",
    "        optimizer.step()\n",
    "        print(\"Epoch {} - Data Point {} - Loss: {}\".format(epoch, i, loss))\n",
    "####################################################\n",
    "\n",
    "### Test the trained network ###\n",
    "for i, current_data in enumerate(data):\n",
    "    out = net(current_data)\n",
    "    print(\"when x = {}, y = {}\".format(current_data, out))\n",
    "\n",
    "plt.plot(hist2, label=\"training curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e6cd9428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=2, out_features=1, bias=False)\n",
      ")\n",
      "[Parameter containing:\n",
      "tensor([[ 1., -1.]], requires_grad=True)]\n",
      "Epoch 0 - Data Point 0 - Loss: 9.0\n",
      "Epoch 0 - Data Point 1 - Loss: 78.85440063476562\n",
      "Epoch 0 - Data Point 2 - Loss: 312.0310363769531\n",
      "Epoch 1 - Data Point 0 - Loss: 1.6960790157318115\n",
      "Epoch 1 - Data Point 1 - Loss: 18.490985870361328\n",
      "Epoch 1 - Data Point 2 - Loss: 109.32250213623047\n",
      "Epoch 2 - Data Point 0 - Loss: 0.5249048471450806\n",
      "Epoch 2 - Data Point 1 - Loss: 0.4949924647808075\n",
      "Epoch 2 - Data Point 2 - Loss: 34.05109786987305\n",
      "Epoch 3 - Data Point 0 - Loss: 3.453439950942993\n",
      "Epoch 3 - Data Point 1 - Loss: 1.2375972270965576\n",
      "Epoch 3 - Data Point 2 - Loss: 13.453826904296875\n",
      "Epoch 4 - Data Point 0 - Loss: 5.560094356536865\n",
      "Epoch 4 - Data Point 1 - Loss: 3.492980718612671\n",
      "Epoch 4 - Data Point 2 - Loss: 7.874255657196045\n",
      "Epoch 5 - Data Point 0 - Loss: 6.492678642272949\n",
      "Epoch 5 - Data Point 1 - Loss: 4.598167419433594\n",
      "Epoch 5 - Data Point 2 - Loss: 6.273415565490723\n",
      "Epoch 6 - Data Point 0 - Loss: 6.821801662445068\n",
      "Epoch 6 - Data Point 1 - Loss: 4.984767913818359\n",
      "Epoch 6 - Data Point 2 - Loss: 5.81882381439209\n",
      "Epoch 7 - Data Point 0 - Loss: 6.919304847717285\n",
      "Epoch 7 - Data Point 1 - Loss: 5.093571186065674\n",
      "Epoch 7 - Data Point 2 - Loss: 5.704937934875488\n",
      "Epoch 8 - Data Point 0 - Loss: 6.942361831665039\n",
      "Epoch 8 - Data Point 1 - Loss: 5.1164069175720215\n",
      "Epoch 8 - Data Point 2 - Loss: 5.684906005859375\n",
      "Epoch 9 - Data Point 0 - Loss: 6.945432662963867\n",
      "Epoch 9 - Data Point 1 - Loss: 5.117887020111084\n",
      "Epoch 9 - Data Point 2 - Loss: 5.685760974884033\n",
      "Epoch 10 - Data Point 0 - Loss: 6.9445881843566895\n",
      "Epoch 10 - Data Point 1 - Loss: 5.1160125732421875\n",
      "Epoch 10 - Data Point 2 - Loss: 5.688826560974121\n",
      "Epoch 11 - Data Point 0 - Loss: 6.94364595413208\n",
      "Epoch 11 - Data Point 1 - Loss: 5.114584445953369\n",
      "Epoch 11 - Data Point 2 - Loss: 5.690755844116211\n",
      "Epoch 12 - Data Point 0 - Loss: 6.9431233406066895\n",
      "Epoch 12 - Data Point 1 - Loss: 5.113866329193115\n",
      "Epoch 12 - Data Point 2 - Loss: 5.691647529602051\n",
      "Epoch 13 - Data Point 0 - Loss: 6.942894458770752\n",
      "Epoch 13 - Data Point 1 - Loss: 5.11357307434082\n",
      "Epoch 13 - Data Point 2 - Loss: 5.69201135635376\n",
      "Epoch 14 - Data Point 0 - Loss: 6.942806720733643\n",
      "Epoch 14 - Data Point 1 - Loss: 5.113461017608643\n",
      "Epoch 14 - Data Point 2 - Loss: 5.692134380340576\n",
      "Epoch 15 - Data Point 0 - Loss: 6.942779064178467\n",
      "Epoch 15 - Data Point 1 - Loss: 5.113430500030518\n",
      "Epoch 15 - Data Point 2 - Loss: 5.692166328430176\n",
      "Epoch 16 - Data Point 0 - Loss: 6.9427714347839355\n",
      "Epoch 16 - Data Point 1 - Loss: 5.113420009613037\n",
      "Epoch 16 - Data Point 2 - Loss: 5.6921796798706055\n",
      "Epoch 17 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 17 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 17 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 18 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 18 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 18 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 19 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 19 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 19 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 20 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 20 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 20 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 21 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 21 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 21 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 22 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 22 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 22 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 23 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 23 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 23 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 24 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 24 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 24 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 25 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 25 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 25 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 26 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 26 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 26 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 27 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 27 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 27 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 28 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 28 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 28 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 29 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 29 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 29 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 30 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 30 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 30 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 31 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 31 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 31 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 32 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 32 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 32 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 33 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 33 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 33 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 34 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 34 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 34 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 35 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 35 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 35 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 36 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 36 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 36 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 37 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 37 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 37 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 38 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 38 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 38 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 39 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 39 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 39 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 40 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 40 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 40 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 41 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 41 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 41 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 42 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 42 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 42 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 43 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 43 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 43 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 44 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 44 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 44 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 45 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 45 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 45 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 46 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 46 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 46 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 47 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 47 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 47 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 48 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 48 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 48 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 49 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 49 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 49 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 50 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 50 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 50 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 51 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 51 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 51 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 52 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 52 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 52 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 53 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 53 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 53 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 54 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 54 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 54 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 55 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 55 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 55 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 56 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 56 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 56 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 57 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 57 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 57 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 58 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 58 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 58 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 59 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 59 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 59 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 60 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 60 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 60 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 61 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 61 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 61 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 62 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 62 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 62 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 63 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 63 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 63 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 64 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 64 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 64 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 65 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 65 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 65 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 66 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 66 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 66 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 67 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 67 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 67 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 68 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 68 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 68 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 69 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 69 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 69 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 70 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 70 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 70 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 71 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 71 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 71 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 72 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 72 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 72 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 73 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 73 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 73 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 74 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 74 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 74 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 75 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 75 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 75 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 76 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 76 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 76 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 77 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 77 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 77 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 78 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 78 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 78 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 79 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 79 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 79 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 80 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 80 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 80 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 81 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 81 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 81 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 82 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 82 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 82 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 83 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 83 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 83 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 84 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 84 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 84 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 85 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 85 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 85 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 86 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 86 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 86 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 87 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 87 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 87 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 88 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 88 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 88 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 89 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 89 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 89 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 90 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 90 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 90 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 91 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 91 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 91 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 92 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 92 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 92 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 93 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 93 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 93 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 94 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 94 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 94 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 95 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 95 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 95 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 96 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 96 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 96 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 97 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 97 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 97 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 98 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 98 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 98 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 99 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 99 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 99 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 100 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 100 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 100 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 101 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 101 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 101 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 102 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 102 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 102 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 103 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 103 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 103 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 104 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 104 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 104 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 105 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 105 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 105 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 106 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 106 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 106 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 107 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 107 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 107 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 108 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 108 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 108 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 109 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 109 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 109 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 110 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 110 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 110 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 111 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 111 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 111 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 112 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 112 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 112 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 113 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 113 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 113 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 114 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 114 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 114 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 115 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 115 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 115 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 116 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 116 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 116 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 117 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 117 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 117 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 118 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 118 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 118 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 119 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 119 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 119 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 120 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 120 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 120 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 121 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 121 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 121 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 122 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 122 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 122 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 123 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 123 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 123 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 124 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 124 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 124 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 125 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 125 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 125 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 126 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 126 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 126 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 127 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 127 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 127 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 128 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 128 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 128 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 129 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 129 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 129 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 130 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 130 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 130 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 131 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 131 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 131 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 132 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 132 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 132 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 133 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 133 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 133 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 134 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 134 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 134 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 135 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 135 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 135 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 136 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 136 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 136 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 137 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 137 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 137 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 138 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 138 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 138 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 139 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 139 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 139 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 140 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 140 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 140 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 141 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 141 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 141 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 142 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 142 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 142 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 143 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 143 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 143 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 144 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 144 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 144 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 145 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 145 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 145 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 146 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 146 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 146 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 147 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 147 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 147 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 148 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 148 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 148 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 149 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 149 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 149 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 150 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 150 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 150 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 151 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 151 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 151 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 152 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 152 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 152 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 153 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 153 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 153 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 154 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 154 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 154 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 155 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 155 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 155 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 156 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 156 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 156 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 157 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 157 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 157 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 158 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 158 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 158 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 159 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 159 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 159 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 160 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 160 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 160 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 161 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 161 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 161 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 162 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 162 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 162 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 163 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 163 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 163 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 164 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 164 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 164 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 165 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 165 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 165 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 166 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 166 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 166 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 167 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 167 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 167 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 168 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 168 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 168 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 169 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 169 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 169 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 170 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 170 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 170 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 171 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 171 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 171 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 172 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 172 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 172 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 173 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 173 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 173 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 174 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 174 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 174 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 175 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 175 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 175 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 176 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 176 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 176 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 177 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 177 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 177 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 178 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 178 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 178 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 179 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 179 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 179 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 180 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 180 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 180 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 181 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 181 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 181 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 182 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 182 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 182 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 183 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 183 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 183 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 184 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 184 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 184 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 185 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 185 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 185 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 186 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 186 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 186 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 187 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 187 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 187 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 188 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 188 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 188 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 189 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 189 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 189 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 190 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 190 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 190 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 191 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 191 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 191 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 192 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 192 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 192 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 193 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 193 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 193 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 194 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 194 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 194 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 195 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 195 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 195 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 196 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 196 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 196 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 197 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 197 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 197 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 198 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 198 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 198 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 199 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 199 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 199 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 200 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 200 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 200 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 201 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 201 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 201 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 202 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 202 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 202 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 203 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 203 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 203 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 204 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 204 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 204 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 205 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 205 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 205 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 206 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 206 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 206 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 207 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 207 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 207 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 208 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 208 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 208 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 209 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 209 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 209 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 210 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 210 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 210 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 211 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 211 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 211 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 212 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 212 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 212 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 213 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 213 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 213 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 214 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 214 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 214 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 215 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 215 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 215 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 216 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 216 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 216 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 217 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 217 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 217 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 218 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 218 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 218 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 219 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 219 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 219 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 220 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 220 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 220 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 221 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 221 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 221 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 222 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 222 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 222 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 223 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 223 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 223 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 224 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 224 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 224 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 225 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 225 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 225 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 226 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 226 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 226 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 227 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 227 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 227 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 228 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 228 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 228 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 229 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 229 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 229 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 230 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 230 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 230 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 231 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 231 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 231 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 232 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 232 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 232 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 233 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 233 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 233 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 234 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 234 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 234 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 235 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 235 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 235 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 236 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 236 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 236 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 237 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 237 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 237 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 238 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 238 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 238 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 239 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 239 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 239 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 240 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 240 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 240 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 241 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 241 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 241 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 242 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 242 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 242 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 243 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 243 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 243 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 244 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 244 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 244 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 245 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 245 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 245 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 246 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 246 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 246 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 247 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 247 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 247 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 248 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 248 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 248 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 249 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 249 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 249 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 250 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 250 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 250 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 251 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 251 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 251 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 252 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 252 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 252 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 253 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 253 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 253 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 254 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 254 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 254 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 255 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 255 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 255 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 256 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 256 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 256 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 257 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 257 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 257 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 258 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 258 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 258 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 259 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 259 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 259 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 260 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 260 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 260 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 261 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 261 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 261 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 262 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 262 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 262 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 263 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 263 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 263 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 264 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 264 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 264 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 265 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 265 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 265 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 266 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 266 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 266 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 267 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 267 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 267 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 268 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 268 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 268 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 269 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 269 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 269 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 270 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 270 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 270 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 271 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 271 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 271 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 272 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 272 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 272 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 273 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 273 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 273 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 274 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 274 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 274 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 275 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 275 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 275 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 276 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 276 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 276 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 277 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 277 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 277 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 278 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 278 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 278 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 279 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 279 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 279 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 280 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 280 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 280 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 281 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 281 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 281 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 282 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 282 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 282 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 283 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 283 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 283 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 284 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 284 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 284 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 285 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 285 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 285 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 286 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 286 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 286 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 287 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 287 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 287 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 288 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 288 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 288 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 289 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 289 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 289 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 290 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 290 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 290 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 291 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 291 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 291 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 292 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 292 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 292 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 293 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 293 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 293 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 294 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 294 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 294 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 295 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 295 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 295 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 296 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 296 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 296 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 297 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 297 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 297 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 298 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 298 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 298 - Data Point 2 - Loss: 5.6921844482421875\n",
      "Epoch 299 - Data Point 0 - Loss: 6.9427690505981445\n",
      "Epoch 299 - Data Point 1 - Loss: 5.113417625427246\n",
      "Epoch 299 - Data Point 2 - Loss: 5.6921844482421875\n",
      "when x = tensor([1., 3.]), y = tensor([3.6349], grad_fn=<SqueezeBackward4>)\n",
      "when x = tensor([2., 6.]), y = tensor([7.2698], grad_fn=<SqueezeBackward4>)\n",
      "when x = tensor([3., 9.]), y = tensor([10.9047], grad_fn=<SqueezeBackward4>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe3e744e1c0>]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2,1,bias=False)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "\n",
    "net.fc1.weight = torch.nn.Parameter(torch.tensor([[1., -1.]], requires_grad=True))\n",
    "\n",
    "print(list(net.parameters()))\n",
    "\n",
    "#input = torch.randn(1,2)\n",
    "#out = net(input)\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "#def criterion(out, label):\n",
    "#    return ((label - out)**2).mean()\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.5) # Changed lr from 0.01 to 0.001 for convergence\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.005)\n",
    "\n",
    "\n",
    "data = torch.tensor([[1.,3.], [2.,6.], [3.,9.]], dtype=torch.float)\n",
    "target = torch.tensor([[1.],[5.],[13.]], dtype=torch.float)\n",
    "hist2 = []\n",
    "\n",
    "\n",
    "############# SGD based update ##############\n",
    "      \n",
    "for epoch in range(300):\n",
    "    for i, current_data in enumerate(data):  \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(data[i]) \n",
    "        loss = criterion(outputs, target[i])  \n",
    "        loss.backward()\n",
    "        hist2.append(loss.detach())\n",
    "        optimizer.step()\n",
    "        print(\"Epoch {} - Data Point {} - Loss: {}\".format(epoch, i, loss))\n",
    "####################################################\n",
    "\n",
    "### Test the trained network ###\n",
    "for i, current_data in enumerate(data):\n",
    "    out = net(current_data)\n",
    "    print(\"when x = {}, y = {}\".format(current_data, out))\n",
    "\n",
    "plt.plot(hist2, label=\"training curve\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
